<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Коан 7 Гетероскедастичность в простой регрессии | Розеттский камень</title>
  <meta name="description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Коан 7 Гетероскедастичность в простой регрессии | Розеттский камень" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Коан 7 Гетероскедастичность в простой регрессии | Розеттский камень" />
  
  <meta name="twitter:description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  

<meta name="author" content="Пуассон, фея и три мексиканских негодяя" />


<meta name="date" content="2019-09-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="paneldata.html"/>
<link rel="next" href="dinpanel.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Напутственное слово</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#installsoft"><i class="fa fa-check"></i><b>1.1</b> # Коан об установке софта</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#--r"><i class="fa fa-check"></i><b>1.1.1</b> Язык программирования R</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#---rstudio--windows-mac-os"><i class="fa fa-check"></i><b>1.1.2</b> Инструкция по установке RStudio для Windows / Mac OS:</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#-"><i class="fa fa-check"></i><b>1.1.3</b> Начало работы</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#--1"><i class="fa fa-check"></i><b>1.1.4</b> Настройка программы</a></li>
<li class="chapter" data-level="1.1.5" data-path="index.html"><a href="index.html#--python"><i class="fa fa-check"></i><b>1.1.5</b> Язык программирования Python</a></li>
<li class="chapter" data-level="1.1.6" data-path="index.html"><a href="index.html#section-1.1.6"><i class="fa fa-check"></i><b>1.1.6</b> Установка</a></li>
<li class="chapter" data-level="1.1.7" data-path="index.html"><a href="index.html#--1"><i class="fa fa-check"></i><b>1.1.7</b> Начало работы</a></li>
<li class="chapter" data-level="1.1.8" data-path="index.html"><a href="index.html#-stata"><i class="fa fa-check"></i><b>1.1.8</b> Программа STATA</a></li>
<li class="chapter" data-level="1.1.9" data-path="index.html"><a href="index.html#-1"><i class="fa fa-check"></i><b>1.1.9</b> Установка:</a></li>
<li class="chapter" data-level="1.1.10" data-path="index.html"><a href="index.html#--2"><i class="fa fa-check"></i><b>1.1.10</b> Начало работы:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="simplereg.html"><a href="simplereg.html"><i class="fa fa-check"></i><b>2</b> Коан о простой линейной регрессии</a><ul>
<li class="chapter" data-level="2.1" data-path="simplereg.html"><a href="simplereg.html#r"><i class="fa fa-check"></i><b>2.1</b> r</a></li>
<li class="chapter" data-level="2.2" data-path="simplereg.html"><a href="simplereg.html#python"><i class="fa fa-check"></i><b>2.2</b> python</a></li>
<li class="chapter" data-level="2.3" data-path="simplereg.html"><a href="simplereg.html#stata"><i class="fa fa-check"></i><b>2.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="poisreg.html"><a href="poisreg.html"><i class="fa fa-check"></i><b>3</b> Модели счетных данных</a><ul>
<li class="chapter" data-level="3.1" data-path="poisreg.html"><a href="poisreg.html#r-1"><i class="fa fa-check"></i><b>3.1</b> r</a></li>
<li class="chapter" data-level="3.2" data-path="poisreg.html"><a href="poisreg.html#python-1"><i class="fa fa-check"></i><b>3.2</b> python</a></li>
<li class="chapter" data-level="3.3" data-path="poisreg.html"><a href="poisreg.html#stata-1"><i class="fa fa-check"></i><b>3.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="disordered.html"><a href="disordered.html"><i class="fa fa-check"></i><b>4</b> Модели неупорядоченного выбора</a><ul>
<li class="chapter" data-level="4.1" data-path="disordered.html"><a href="disordered.html#instruments"><i class="fa fa-check"></i><b>4.1</b> # Коан об инcтрументах для простой регрессии</a></li>
<li class="chapter" data-level="4.2" data-path="disordered.html"><a href="disordered.html#r-2"><i class="fa fa-check"></i><b>4.2</b> r</a></li>
<li class="chapter" data-level="4.3" data-path="disordered.html"><a href="disordered.html#stata-2"><i class="fa fa-check"></i><b>4.3</b> stata</a></li>
<li class="chapter" data-level="4.4" data-path="disordered.html"><a href="disordered.html#python-2"><i class="fa fa-check"></i><b>4.4</b> python</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="arma.html"><a href="arma.html"><i class="fa fa-check"></i><b>5</b> ARMA</a><ul>
<li class="chapter" data-level="5.1" data-path="arma.html"><a href="arma.html#r-3"><i class="fa fa-check"></i><b>5.1</b> r</a></li>
<li class="chapter" data-level="5.2" data-path="arma.html"><a href="arma.html#python-3"><i class="fa fa-check"></i><b>5.2</b> python</a></li>
<li class="chapter" data-level="5.3" data-path="arma.html"><a href="arma.html#stata-3"><i class="fa fa-check"></i><b>5.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="paneldata.html"><a href="paneldata.html"><i class="fa fa-check"></i><b>6</b> Панельные данные</a></li>
<li class="chapter" data-level="7" data-path="heterosked.html"><a href="heterosked.html"><i class="fa fa-check"></i><b>7</b> Гетероскедастичность в простой регрессии</a><ul>
<li class="chapter" data-level="7.1" data-path="heterosked.html"><a href="heterosked.html#r-4"><i class="fa fa-check"></i><b>7.1</b> r</a></li>
<li class="chapter" data-level="7.2" data-path="heterosked.html"><a href="heterosked.html#python-4"><i class="fa fa-check"></i><b>7.2</b> python</a></li>
<li class="chapter" data-level="7.3" data-path="heterosked.html"><a href="heterosked.html#stata-4"><i class="fa fa-check"></i><b>7.3</b> stata</a></li>
<li class="chapter" data-level="7.4" data-path="heterosked.html"><a href="heterosked.html#pca"><i class="fa fa-check"></i><b>7.4</b> # Коан о методе главных компонент</a></li>
<li class="chapter" data-level="7.5" data-path="heterosked.html"><a href="heterosked.html#r-5"><i class="fa fa-check"></i><b>7.5</b> r</a></li>
<li class="chapter" data-level="7.6" data-path="heterosked.html"><a href="heterosked.html#stata-5"><i class="fa fa-check"></i><b>7.6</b> stata</a></li>
<li class="chapter" data-level="7.7" data-path="heterosked.html"><a href="heterosked.html#python-5"><i class="fa fa-check"></i><b>7.7</b> python</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="dinpanel.html"><a href="dinpanel.html"><i class="fa fa-check"></i><b>8</b> Динамические панели</a></li>
<li class="chapter" data-level="9" data-path="tobit-heckit.html"><a href="tobit-heckit.html"><i class="fa fa-check"></i><b>9</b> TOBIT, HECKIT</a></li>
<li class="chapter" data-level="10" data-path="treatment.html"><a href="treatment.html"><i class="fa fa-check"></i><b>10</b> Treatment effect</a></li>
<li class="chapter" data-level="11" data-path="compatability.html"><a href="compatability.html"><i class="fa fa-check"></i><b>11</b> Что-то там про совместимость и языки</a></li>
<li class="chapter" data-level="12" data-path="dict.html"><a href="dict.html"><i class="fa fa-check"></i><b>12</b> Словарь</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Розеттский камень</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="heterosked" class="section level1">
<h1><span class="header-section-number">Коан 7</span> Гетероскедастичность в простой регрессии</h1>
<blockquote>
<p>Одним из нарушений условий ТГМ является гетероскедастичность, возникающая ввиду неодинаковых дисперсий для разных наблюдений. Она нежелательна ввиду того, что оценки МНК не являются эффективными (но остаются несмещёнными), и предпосылки для использования <code>t</code>-статистик нарушены, что даёт неверный результат о значимости коэффициентов.</p>
</blockquote>
<p>Этот коан благословит Вас на поиски гетероскедастичности и просветит о способах борьбы с ней.</p>
<p>Будем анализировать гетероскедастичность на данных о стоимости квартир.</p>
<div id="r-4" class="section level2">
<h2><span class="header-section-number">7.1</span> r</h2>
<p>Вызовем <strong>r</strong> в помощь в охоте на гетероскедастичность. Импортируем его оружейные пакеты.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb382-1" data-line-number="1"><span class="kw">library</span>(rio) <span class="co"># импорт и экспорт данных в разных форматах</span></a>
<a class="sourceLine" id="cb382-2" data-line-number="2"><span class="kw">library</span>(dplyr) <span class="co"># манипуляции с данными</span></a>
<a class="sourceLine" id="cb382-3" data-line-number="3"><span class="kw">library</span>(lmtest) <span class="co"># тест Бройша-Пагана</span></a>
<a class="sourceLine" id="cb382-4" data-line-number="4"><span class="kw">library</span>(sandwich) <span class="co"># оценка дисперсии при гетероскедастичности</span></a>
<a class="sourceLine" id="cb382-5" data-line-number="5"><span class="kw">library</span>(UStatBookABSC) <span class="co"># WLS</span></a></code></pre></div>
<pre><code>Error in library(UStatBookABSC): there is no package called &#39;UStatBookABSC&#39;</code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb384-1" data-line-number="1"><span class="kw">library</span> (estimatr) <span class="co"># получение робастных оценок</span></a>
<a class="sourceLine" id="cb384-2" data-line-number="2"><span class="kw">library</span>(ggpubr) <span class="co"># для графиков</span></a>
<a class="sourceLine" id="cb384-3" data-line-number="3"><span class="kw">library</span>(skimr) <span class="co"># для описательных статистик</span></a></code></pre></div>
<p>Импортируем наш dataset, <code>flats.dta</code>:</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb385-1" data-line-number="1">flats=<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;data/flats.dta&quot;</span>)</a></code></pre></div>
<p>Рассмотрим описательные статистики загруженного датасета.</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb386-1" data-line-number="1"><span class="kw">skim</span>(flats)</a></code></pre></div>
<pre><code>Skim summary statistics
 n obs: 773 
 n variables: 44 

── Variable type:character ───────────────────────────────────────────────────────────────────────────────────────────────────────
                   variable missing complete   n min max empty n_unique
                      okrug       0      773 773   0   4     1        4
 sanuzel__1_razdel__0_sovm_       0      773 773   1   2     0        3

── Variable type:numeric ─────────────────────────────────────────────────────────────────────────────────────────────────────────
         variable missing complete   n        mean         sd         p0
              bal       0      773 773       0.53        0.5        0   
            brick       0      773 773       0.16        0.37       0   
             dist       0      773 773      12.19        4.66       5   
            floor       0      773 773       0.83        0.38       0   
           floor1       0      773 773       0.097       0.3        0   
           floor2       0      773 773       0.074       0.26       0   
           floors       0      773 773      15.71        9.09       3   
            kitsp       0      773 773       8.09        2.85       2   
           livesp       0      773 773      21.45        7.25       8   
          ln_dist       0      773 773       2.43        0.4        1.61
       ln_dist_sq       0      773 773       6.04        1.88       2.59
        ln_floors       0      773 773       2.59        0.59       1.1 
     ln_floors_sq       0      773 773       7.05        3.03       1.21
         ln_kitsp       0      773 773       2.02        0.41       0.69
      ln_kitsp_sq       0      773 773       4.24        1.48       0.48
        ln_livesp       0      773 773       3.02        0.27       2.08
     ln_livesp_sq       0      773 773       9.22        1.74       4.32
      ln_metrdist       0      773 773       2.04        0.55       0   
   ln_metrdist_sq       0      773 773       4.49        2.07       0   
 ln_metrdist_walk       0      773 773       0.97        1.09       0   
        ln_nfloor       0      773 773       1.7         0.89       0   
     ln_nfloor_sq       0      773 773       3.69        3.04       0   
   ln_price_meter       0      773 773      12.19        0.3       11.35
    ln_price_metr       0      773 773      12.19        0.3       11.35
         ln_totsp       0      773 773       3.6         0.28       2.71
      ln_totsp_sq       0      773 773      13.01        1.94       7.33
        ln_totsp2       0      773 773      13.01        1.94       7.33
        ln_totsp3       0      773 773      28.34        8.55       8.99
         metrdist       0      773 773       8.83        4.44       1   
                n       0      773 773     395.48      228.89       1   
              new       0      773 773       0.31        0.46       0   
           nfloor       0      773 773       7.93        7.99       1   
       non_livesp       0      773 773       8.29        4.65       0   
               nw       0      773 773       0.41        0.49       0   
            price       0      773 773 7548674.66  2492693.71 3300000   
      price_meter       0      773 773  207308.48    74861.22   84930.44
            rooms       0      773 773       1           0          1   
               sw       0      773 773       0.39        0.49       0   
              tel       0      773 773       0.91        0.3        0   
            totsp       0      773 773      37.82        9.9       15   
                w       0      773 773       0.2         0.4        0   
             walk       0      773 773       0.46        0.5        0   
        p25        p50        p75        p100     hist
       0          1          1        1       ▇▁▁▁▁▁▁▇
       0          0          0        1       ▇▁▁▁▁▁▁▂
       9         11.5       15       25.5     ▇▆▇▇▅▁▁▂
       1          1          1        1       ▂▁▁▁▁▁▁▇
       0          0          0        1       ▇▁▁▁▁▁▁▁
       0          0          0        1       ▇▁▁▁▁▁▁▁
       9         14         19       48       ▃▇▃▂▁▁▂▁
       6          8         10       24       ▂▅▇▂▁▁▁▁
      18         19         21       65       ▁▇▁▁▁▁▁▁
       2.2        2.44       2.71     3.24    ▃▃▃▇▇▇▃▂
       4.83       5.97       7.33    10.49    ▃▂▆▆▇▃▁▂
       2.2        2.64       2.94     3.87    ▁▃▁▅▇▆▃▂
       4.83       6.96       8.67    14.99    ▃▁▇▇▂▂▃▁
       1.79       2.08       2.3      3.18    ▁▁▁▃▇▅▁▁
       3.21       4.32       5.3     10.1     ▂▂▆▇▆▁▁▁
       2.89       2.94       3.04     4.17    ▁▁▂▇▁▁▁▁
       8.35       8.67       9.27    17.43    ▁▁▇▂▁▁▁▁
       1.61       2.3        2.3      3.69    ▁▁▁▃▇▃▁▁
       2.59       5.3        5.3     13.61    ▂▆▃▇▃▁▁▁
       0          0          2.08     3.69    ▇▁▁▂▃▁▁▁
       1.1        1.79       2.4      4.84    ▃▆▇▇▅▂▁▁
       1.21       3.21       5.75    23.47    ▇▅▂▁▁▁▁▁
      12.03      12.15      12.32    13.3     ▁▁▆▇▂▁▁▁
      12.03      12.15      12.32    13.3     ▁▁▆▇▂▁▁▁
       3.47       3.64       3.74     4.32    ▁▁▁▅▇▂▂▁
      12.01      13.23      13.97    18.64    ▁▁▁▇▇▂▁▁
      12.01      13.23      13.97    18.64    ▁▁▁▇▇▂▁▁
      24.15      25.53      28.22    72.74    ▁▃▇▁▁▁▁▁
       5         10         10       40       ▅▇▃▁▁▁▁▁
     196        397        595      788       ▇▇▇▇▇▇▇▇
       0          0          1        1       ▇▁▁▁▁▁▁▃
       3          6         11      127       ▇▁▁▁▁▁▁▁
       5          8         11       25       ▅▅▇▇▂▁▁▁
       0          0          1        1       ▇▁▁▁▁▁▁▆
 5750000    6700000    8600000        1.8e+07 ▁▇▃▂▂▁▁▁
  167187.5   189393.9   223076.9  6e+05       ▂▇▂▁▁▁▁▁
       1          1          1        1       ▁▁▁▇▁▁▁▁
       0          0          1        1       ▇▁▁▁▁▁▁▅
       1          1          1        3       ▁▁▇▁▁▁▁▁
      32         38         42       75       ▂▁▇▇▂▂▁▁
       0          0          0        1       ▇▁▁▁▁▁▁▂
       0          0          1        1       ▇▁▁▁▁▁▁▇</code></pre>
<p>Построим простую линейную регрессионную модель, на которой будем проверять гетероскедастичность.</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb388-1" data-line-number="1">reg =<span class="st"> </span><span class="kw">lm</span>(ln_price_metr <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ln_livesp <span class="op">+</span><span class="st"> </span>ln_kitsp <span class="op">+</span><span class="st"> </span>ln_dist <span class="op">+</span><span class="st"> </span>ln_metrdist, <span class="dt">data=</span>flats)</a>
<a class="sourceLine" id="cb388-2" data-line-number="2"><span class="kw">summary</span>(reg)</a></code></pre></div>
<pre><code>
Call:
lm(formula = ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + 
    ln_metrdist, data = flats)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.62723 -0.16125 -0.00845  0.13614  0.77618 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 14.19920    0.13492 105.243  &lt; 2e-16 ***
ln_livesp   -0.16053    0.03723  -4.312 1.83e-05 ***
ln_kitsp    -0.29913    0.02300 -13.007  &lt; 2e-16 ***
ln_dist     -0.33025    0.02367 -13.952  &lt; 2e-16 ***
ln_metrdist -0.05738    0.01560  -3.679 0.000251 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.2309 on 768 degrees of freedom
Multiple R-squared:  0.4179,    Adjusted R-squared:  0.4149 
F-statistic: 137.9 on 4 and 768 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Проверим наличие гетероскедастичности визуально. Построим зависимости цены квартир от объясняющих факторов.</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb390-1" data-line-number="1">kit =<span class="st"> </span><span class="kw">ggplot</span>(flats) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ln_kitsp, <span class="dt">y =</span> ln_price_metr)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb390-2" data-line-number="2"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Площадь кухни, кв.м&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Цена квартиры, $1000&quot;</span>, </a>
<a class="sourceLine" id="cb390-3" data-line-number="3">  <span class="dt">title =</span> <span class="st">&quot;Стоимость квартир в Москве&quot;</span>)</a>
<a class="sourceLine" id="cb390-4" data-line-number="4">live =<span class="st"> </span><span class="kw">ggplot</span>(flats) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ln_livesp, <span class="dt">y =</span> ln_price_metr)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb390-5" data-line-number="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Жилая площадь, кв.м&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Цена квартиры, $1000&quot;</span>, </a>
<a class="sourceLine" id="cb390-6" data-line-number="6">  <span class="dt">title =</span> <span class="st">&quot;Стоимость квартир в Москве&quot;</span>)</a>
<a class="sourceLine" id="cb390-7" data-line-number="7">dist =<span class="st"> </span><span class="kw">ggplot</span>(flats) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ln_dist, <span class="dt">y =</span> ln_price_metr)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb390-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Расстояние до центра, м&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Цена квартиры, $1000&quot;</span>,</a>
<a class="sourceLine" id="cb390-9" data-line-number="9">  <span class="dt">title =</span> <span class="st">&quot;Стоимость квартир в Москве&quot;</span>)</a>
<a class="sourceLine" id="cb390-10" data-line-number="10">metrdist =<span class="st"> </span><span class="kw">ggplot</span>(flats) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ln_metrdist, <span class="dt">y =</span> ln_price_metr)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb390-11" data-line-number="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Расстояние до метро, м&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Цена квартиры, $1000&quot;</span>, </a>
<a class="sourceLine" id="cb390-12" data-line-number="12">  <span class="dt">title =</span> <span class="st">&quot;Стоимость квартир в Москве&quot;</span>)</a>
<a class="sourceLine" id="cb390-13" data-line-number="13"></a>
<a class="sourceLine" id="cb390-14" data-line-number="14"><span class="kw">ggarrange</span>(kit, live, dist, metrdist, <span class="dt">ncol=</span><span class="dv">2</span>, <span class="dt">nrow=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="10-heterosked_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" />
Из сета красивых графиков видно, что гетероскедастичность присутствует. В частности, подозрительны переменные <code>ln_kitsp</code> и <code>ln_metrdist</code>.</p>
<p>Проверим наличие гетероскедастичности с помощью тестов. Начнём с теста Уайта. Он неконструктивный, он может лишь показать наличие гетероскедастичности, асимптотический. Нормальность остатков в предпосылках не требуется, подразумевается, что <span class="math display">\[E{\varepsilon^4_i} = const\]</span>.</p>
<p><span class="math display">\[
\begin{cases}
H_0: \sigma^2_i = \sigma^2 \\
H_1: \sigma^2_i \neq = \sigma^2 \\
\end{cases}
\]</span></p>
<p>На первом шаге тест сохраняет остатки от построения начальной регрессии.
<span class="math display">\[
\hat{\ln{(pricemetr_i)}} = \hat{\beta}_0 + \hat{\beta}_{\ln{(kitsp)}} \cdot \ln{(kitsp_i)} + \hat{\beta}_{\ln{(livesp)}}\cdot \ln{(livesp_i)} + \hat{\beta}_{\ln{(dist)}}\cdot \ln{(dist_i)} + \hat{\beta}_{\ln{(metrdist)}}\cdot \ln{(metrdist_i)}
\]</span>
На втором - строится вспомогательная регрессия (X_j-вектор j-го фактора).
<span class="math display">\[
\hat{e}^2_i = \hat{\alpha}_0 + \sum_{j=1}^{k} \hat{\alpha}_j \cdot X_j + \sum_{j=1}^{k} \hat{\gamma}_j \cdot X^2_j + \sum_{j &lt; m}^{k} \hat{\delta}_j X_j \cdot X_m
\]</span></p>
<p><code>R-squared</code> построенной вспомогательной регрессии должен быть распределён как:
<span class="math display">\[
n \cdot R^2_{aux} \sim \chi^2_{K-1}
\]</span>
где <code>K</code> – число факторов во вспомогательной регрессии.</p>
<p>Тест Уайта реализуется (ручками) как:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb391-1" data-line-number="1"><span class="kw">bptest</span>(reg, <span class="dt">varformula =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ln_livesp <span class="op">+</span><span class="st"> </span>ln_kitsp <span class="op">+</span><span class="st"> </span>ln_dist <span class="op">+</span><span class="st"> </span>ln_metrdist <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_livesp <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_kitsp <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_dist <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_metrdist <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_livesp <span class="op">*</span><span class="st"> </span>ln_kitsp) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_livesp <span class="op">*</span><span class="st"> </span>ln_dist) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_livesp <span class="op">*</span><span class="st"> </span>ln_metrdist) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_kitsp <span class="op">*</span><span class="st"> </span>ln_dist) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_kitsp <span class="op">*</span><span class="st"> </span>ln_metrdist) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(ln_dist <span class="op">*</span><span class="st"> </span>ln_metrdist), <span class="dt">data=</span>flats)</a></code></pre></div>
<pre><code>
    studentized Breusch-Pagan test

data:  reg
BP = 89.02, df = 14, p-value = 5.81e-13</code></pre>
<p>Тест Уайта выявил гетероскедастичность.</p>
<p>Тест Бройша-Пагана – обобщённый вариант теста Уайта. В тесте Бройша-Пагана во вспомогательной регрессии можно брать любые функции от регрессоров, в тесте Уайта - регрессоры, их квадраты и кросс-произведения. Тест Бройша-Пагана является асимптотическим.</p>
<p><span class="math display">\[
\begin{cases}
H_0: \sigma^2_i = \sigma^2 \\
H_1: \sigma^2_i \propto f(\alpha_0 + \alpha_1 \cdot Z_1 +  \ldots + \alpha_p \cdot Z_p) \\
\end{cases}
\]</span></p>
<p>Классическая версия Бройша-Пагана строится на основе метода максимального правдоподобия. Предпосылками классической версии теста являются нормальность остатков, существование у функции дисперсии из альтернативной гипотезы первой и второй производной. Считается LM-статистика, которая, при верной основной гипотезе об отсутствии гетероскедастичности, имеет хи-квадратное распределение с p-1 степенью свободы.</p>
<p>Классическая версия Бройша-Пагана реализуется в <strong>r</strong> по команде:</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb393-1" data-line-number="1"><span class="kw">bptest</span>(reg, <span class="dt">studentize=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>
    Breusch-Pagan test

data:  reg
BP = 18.39, df = 4, p-value = 0.001035</code></pre>
<p>Современная модификация теста не требует нормальности остатков, лишь <span class="math display">\[{\mathbb E}({\varepsilon^4_i}) = const\]</span>.
На первом шаге строится исходная регрессия и сохраняются остатки. Затем строится состоятельная оценка дисперсии:
<span class="math display">\[
\hat{\sigma}^2 = \frac{1}{n} \cdot \sum_{i=1}^{n} {e^2_i}
\]</span>
Потом строится вспомогательная регрессия:
<span class="math display">\[
\frac{e^2}{\hat{\sigma}^2} = \alpha_0 + \alpha_1 \cdot Z_1 + \ldots + \alpha_p \cdot Z_p + u
\]</span>
И рассчитывается тестовая статистика:
<span class="math display">\[
\frac{RSS_{aux}}{2} \sim \chi^2_{p}
\]</span>
Модифицированная версия теста Бройша-Пагана реализуется по команде:</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb395-1" data-line-number="1"><span class="kw">bptest</span>(reg)</a></code></pre></div>
<pre><code>
    studentized Breusch-Pagan test

data:  reg
BP = 15.778, df = 4, p-value = 0.003332</code></pre>
<p>Причем, если отдельно не указать спецификацию вспомогательной регрессии, то <code>bptest()</code> возьмёт все регрессоры исходной модели.</p>
<p>В обеих версиях теста Бройша-Пагана гетероскедастичность обнаружена.</p>
<p>Ещё есть тест Голдфелда-Квандта.</p>
<p><span class="math display">\[
\begin{cases}
H_0: \sigma^2_i = \sigma^2 \\
H_1: \sigma^2_i \propto X_i \\
\end{cases}
\]</span></p>
<p>Этот тест предполагает нормальность остатков и является неасимптотическим.</p>
<p>Процедура:</p>
<p>Сначала все наблюдения сортируются по возрастанию абсолютного значения фактора, вызывающего гетероскедастичность.</p>
<p>Затем отсортированный ряд по фактору делится на 3 примерно равные части. Считаются гетероскедастичности по первой и третьей части ряда.
Строится <code>F</code>-статистика:
<span class="math display">\[
\frac{RSS_2}{RSS_1} \sim F_{r - k, r-k}
\]</span></p>
<p>где <code>r</code> - размер первой и третьей частей отсортированного ряда.</p>
<p>Данный тест в <strong>r</strong> реализуется по командам (предполагается, что дисперсии пропорциональны переменной <code>ln_kitsp</code>):</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb397-1" data-line-number="1">flats_ordered =<span class="st"> </span>flats[<span class="kw">order</span>(flats<span class="op">$</span>ln_kitsp), ]</a>
<a class="sourceLine" id="cb397-2" data-line-number="2">reg_gqtest =<span class="st"> </span><span class="kw">lm</span>(ln_price_metr <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ln_livesp <span class="op">+</span><span class="st"> </span>ln_kitsp <span class="op">+</span><span class="st"> </span>ln_dist <span class="op">+</span><span class="st"> </span>ln_metrdist, <span class="dt">data=</span>flats_ordered)</a>
<a class="sourceLine" id="cb397-3" data-line-number="3"><span class="kw">gqtest</span>(reg_gqtest, <span class="dt">fraction=</span><span class="fl">0.34</span>) <span class="co"># посередине отсортированного ряда лежит 34% наблюдений</span></a></code></pre></div>
<pre><code>
    Goldfeld-Quandt test

data:  reg_gqtest
GQ = 1.1072, df1 = 251, df2 = 250, p-value = 0.2106
alternative hypothesis: variance increases from segment 1 to 2</code></pre>
<p>Будет также полезным познакомиться с методами борьбы с гетероскедастичностью.</p>
<p>Способ 1. Взвешенный МНК. Веса – оценка обратной дисперсии переменной, вызывающей гетероскедачность.
То есть оценим регрессию:
<span class="math display">\[
\frac{\ln{(pricemetr_i)}}{\hat{\sigma}_i} = 
\frac{\beta_0}{\hat{\sigma}_i} + 
\frac{\beta_{\ln{(kitsp)}} \cdot \ln{(kitsp_i)}}{\hat{\sigma}_i} + \frac{\beta_{\ln{(livesp)}} \cdot \ln{(livesp_i)}}{\hat{\sigma}_i} + \frac{\beta_{\ln{(dist)}} \cdot \ln{(dist_i)}}{\hat{\sigma}_i} + \frac{\beta_{\ln{(metrdist)}} \cdot \ln{(metrdist_i)}}{\hat{\sigma}_i} + \frac{\varepsilon_i}{\hat{\sigma}_i}
\]</span></p>
<p>В <strong>r</strong> это можно сделать так:</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb399-1" data-line-number="1">reg_wls =<span class="st"> </span><span class="kw">lm</span>(ln_price_metr <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ln_livesp <span class="op">+</span><span class="st"> </span>ln_kitsp <span class="op">+</span><span class="st"> </span>ln_dist <span class="op">+</span><span class="st"> </span>ln_metrdist, <span class="dt">data=</span>flats, <span class="dt">weights =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">fitted</span>(<span class="kw">lm</span>(<span class="kw">abs</span>(<span class="kw">residuals</span>(reg)) <span class="op">~</span><span class="st"> </span>ln_kitsp)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb399-2" data-line-number="2"><span class="kw">summary</span>(reg_wls)</a></code></pre></div>
<pre><code>
Call:
lm(formula = ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + 
    ln_metrdist, data = flats, weights = 1/(1/fitted(lm(abs(residuals(reg)) ~ 
    ln_kitsp))^2))

Weighted Residuals:
      Min        1Q    Median        3Q       Max 
-0.105299 -0.029659 -0.001107  0.025053  0.155867 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 14.28313    0.13557 105.357  &lt; 2e-16 ***
ln_livesp   -0.16102    0.03849  -4.183  3.2e-05 ***
ln_kitsp    -0.33901    0.02245 -15.098  &lt; 2e-16 ***
ln_dist     -0.33075    0.02406 -13.749  &lt; 2e-16 ***
ln_metrdist -0.05859    0.01587  -3.691 0.000239 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.04242 on 768 degrees of freedom
Multiple R-squared:  0.4683,    Adjusted R-squared:  0.4655 
F-statistic: 169.1 on 4 and 768 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Способ 2. Робастные оценки Уайта.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb401-1" data-line-number="1"><span class="kw">coeftest</span>(reg, <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(reg, <span class="st">&quot;HC0&quot;</span>))</a></code></pre></div>
<pre><code>
t test of coefficients:

             Estimate Std. Error  t value  Pr(&gt;|t|)    
(Intercept) 14.199195   0.158790  89.4210 &lt; 2.2e-16 ***
ln_livesp   -0.160528   0.040845  -3.9302 9.253e-05 ***
ln_kitsp    -0.299130   0.028398 -10.5336 &lt; 2.2e-16 ***
ln_dist     -0.330251   0.023965 -13.7803 &lt; 2.2e-16 ***
ln_metrdist -0.057375   0.014528  -3.9494 8.555e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Робастные оценки коэффициентов регрессии получаются состоятельными.</p>
</div>
<div id="python-4" class="section level2">
<h2><span class="header-section-number">7.2</span> python</h2>
<p>Теперь попробуем проделать эти шаги в <strong>python</strong>.</p>
<p>Импотируем необходимые пакеты.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb403-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb403-2" data-line-number="2"><span class="im">import</span> pandas <span class="im">as</span> pd <span class="co"># чтение файлов</span></a>
<a class="sourceLine" id="cb403-3" data-line-number="3"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt <span class="co"># построение графиков</span></a>
<a class="sourceLine" id="cb403-4" data-line-number="4"><span class="im">import</span> seaborn <span class="im">as</span> sns <span class="co"># построение графиков</span></a>
<a class="sourceLine" id="cb403-5" data-line-number="5"><span class="im">import</span> statsmodels.api <span class="im">as</span> sm <span class="co"># тесты</span></a>
<a class="sourceLine" id="cb403-6" data-line-number="6"><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols, WLS <span class="co"># построение регрессии</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ImportError: cannot import name &#39;WLS&#39; from &#39;statsmodels.formula.api&#39; (/home/boris/anaconda3/lib/python3.7/site-packages/statsmodels/formula/api.py)

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb405"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb405-1" data-line-number="1"><span class="im">import</span> statsmodels</a>
<a class="sourceLine" id="cb405-2" data-line-number="2"><span class="im">import</span> statsmodels.stats.diagnostic <span class="im">as</span> sm_diagnostic <span class="co"># тест Бройша-Пагана</span></a></code></pre></div>
<p>Загрузим исследуемый датасет.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb406-1" data-line-number="1">flats <span class="op">=</span> pd.read_stata(<span class="st">&quot;data/flats.dta&quot;</span>)</a></code></pre></div>
<p>Построим линейную регрессионную модель.</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb407-1" data-line-number="1">reg <span class="op">=</span> ols(<span class="st">&quot;ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + ln_metrdist&quot;</span>, flats).fit()</a>
<a class="sourceLine" id="cb407-2" data-line-number="2">reg.summary()</a></code></pre></div>
<pre><code>&lt;class &#39;statsmodels.iolib.summary.Summary&#39;&gt;
&quot;&quot;&quot;
                            OLS Regression Results                            
==============================================================================
Dep. Variable:          ln_price_metr   R-squared:                       0.418
Model:                            OLS   Adj. R-squared:                  0.415
Method:                 Least Squares   F-statistic:                     137.9
Date:                 Чт, 26 сен 2019   Prob (F-statistic):           9.06e-89
Time:                        17:31:09   Log-Likelihood:                 38.744
No. Observations:                 773   AIC:                            -67.49
Df Residuals:                     768   BIC:                            -44.24
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept      14.1992      0.135    105.243      0.000      13.934      14.464
ln_livesp      -0.1605      0.037     -4.312      0.000      -0.234      -0.087
ln_kitsp       -0.2991      0.023    -13.007      0.000      -0.344      -0.254
ln_dist        -0.3303      0.024    -13.952      0.000      -0.377      -0.284
ln_metrdist    -0.0574      0.016     -3.679      0.000      -0.088      -0.027
==============================================================================
Omnibus:                       25.080   Durbin-Watson:                   1.309
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.855
Skew:                           0.425   Prob(JB):                     1.47e-06
Kurtosis:                       3.331   Cond. No.                         83.2
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
&quot;&quot;&quot;</code></pre>
<p>Визуализируем зависимости регрессоров и регрессанта.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb409-1" data-line-number="1">sns.pairplot(flats, x_vars<span class="op">=</span>[<span class="st">&quot;ln_metrdist&quot;</span>, <span class="st">&quot;ln_kitsp&quot;</span>, <span class="st">&quot;ln_livesp&quot;</span>, <span class="st">&quot;ln_dist&quot;</span>], y_vars<span class="op">=</span>[<span class="st">&quot;ln_price_metr&quot;</span>])</a></code></pre></div>
<pre><code>&lt;seaborn.axisgrid.PairGrid object at 0x7f4f7c44ec50&gt;</code></pre>
<div class="sourceCode" id="cb411"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb411-1" data-line-number="1">plt.show()</a></code></pre></div>
<p><img src="10-heterosked_files/figure-html/unnamed-chunk-16-1.png" width="960" style="display: block; margin: auto;" />
Графики всё такие же красивые, как и в предыдущем пункте:) Подозрительны переменные <code>ln_kitsp</code> и <code>ln_metrdist</code>
Проведём тесты на выявление гетероскедастичности в <strong>python</strong>.</p>
<p>Рассмотрим тест Бройша-Пагана на всех факторах.</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb412-1" data-line-number="1">resid <span class="op">=</span> reg.resid</a>
<a class="sourceLine" id="cb412-2" data-line-number="2">X <span class="op">=</span> flats[[<span class="st">&#39;ln_livesp&#39;</span>, <span class="st">&#39;ln_kitsp&#39;</span>, <span class="st">&#39;ln_dist&#39;</span>, <span class="st">&#39;ln_metrdist&#39;</span>]]</a>
<a class="sourceLine" id="cb412-3" data-line-number="3">sm_diagnostic.het_breuschpagan(resid<span class="op">=</span>resid, exog_het<span class="op">=</span>X)</a></code></pre></div>
<pre><code>(242.3887600398093, 2.8968538727030817e-52, 87.82180928008509, 1.8044481939798466e-61)</code></pre>
<p>Интерпретация результатов теста:</p>
<p>Первое из выданных значений - значение тестовой статистики теста Бройша-Пагана, второе - значение p-value для выданной тестовой статистики. Третье и четвёртое - значения тестовой статистики и её p-value для на уровне значимости 5% (табличное). Гетероскедастичность присутствует.</p>
<p>Посмотрим на тест Голдфелда-Квандта по переменной <code>ln_kitsp</code>.</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb414-1" data-line-number="1">sm_diagnostic.het_goldfeldquandt(y<span class="op">=</span>flats[<span class="st">&quot;ln_price_metr&quot;</span>], x<span class="op">=</span>X, alternative<span class="op">=</span><span class="st">&quot;two-sided&quot;</span>)</a></code></pre></div>
<pre><code>(0.5313884697477882, 8.827144512209523e-10, &#39;two-sided&#39;)</code></pre>
<p>Значение p-value близко к 0, следовательно, основная гипотеза о гомоскедастичности отвергается.</p>
<p>Теперь о способах борьбы с гетероскедастичностью.</p>
<p>Способ 1. Взвешенный МНК.</p>
<p>Взвешиваем по стандартному отклонению фактора <code>ln_kitsp</code>.</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb416-1" data-line-number="1">reg_wls <span class="op">=</span> statsmodels.regression.linear_model.WLS(flats[<span class="st">&quot;ln_price_metr&quot;</span>], X, weights<span class="op">=</span>flats[<span class="st">&#39;ln_kitsp&#39;</span>])</a>
<a class="sourceLine" id="cb416-2" data-line-number="2">reg_wls_results <span class="op">=</span> reg_wls.fit()</a>
<a class="sourceLine" id="cb416-3" data-line-number="3">reg_wls_results.summary()</a></code></pre></div>
<pre><code>&lt;class &#39;statsmodels.iolib.summary.Summary&#39;&gt;
&quot;&quot;&quot;
                                 WLS Regression Results                                
=======================================================================================
Dep. Variable:          ln_price_metr   R-squared (uncentered):                   0.995
Model:                            WLS   Adj. R-squared (uncentered):              0.995
Method:                 Least Squares   F-statistic:                          3.763e+04
Date:                 Чт, 26 сен 2019   Prob (F-statistic):                        0.00
Time:                        17:31:09   Log-Likelihood:                         -997.20
No. Observations:                 773   AIC:                                      2002.
Df Residuals:                     769   BIC:                                      2021.
Df Model:                           4                                                  
Covariance Type:            nonrobust                                                  
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
ln_livesp       2.9582      0.071     41.469      0.000       2.818       3.098
ln_kitsp       -0.1256      0.095     -1.316      0.189      -0.313       0.062
ln_dist         1.1813      0.068     17.317      0.000       1.047       1.315
ln_metrdist     0.2429      0.057      4.259      0.000       0.131       0.355
==============================================================================
Omnibus:                       13.564   Durbin-Watson:                   1.132
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               23.475
Skew:                          -0.050   Prob(JB):                     7.99e-06
Kurtosis:                       3.848   Cond. No.                         17.4
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
&quot;&quot;&quot;</code></pre>
<p>Способ 2. Использование робастных оценок.</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb418-1" data-line-number="1">reg_robust <span class="op">=</span> reg.get_robustcov_results()</a>
<a class="sourceLine" id="cb418-2" data-line-number="2">reg_robust.summary()</a></code></pre></div>
<pre><code>&lt;class &#39;statsmodels.iolib.summary.Summary&#39;&gt;
&quot;&quot;&quot;
                            OLS Regression Results                            
==============================================================================
Dep. Variable:          ln_price_metr   R-squared:                       0.418
Model:                            OLS   Adj. R-squared:                  0.415
Method:                 Least Squares   F-statistic:                     102.5
Date:                 Чт, 26 сен 2019   Prob (F-statistic):           5.95e-70
Time:                        17:31:09   Log-Likelihood:                 38.744
No. Observations:                 773   AIC:                            -67.49
Df Residuals:                     768   BIC:                            -44.24
Df Model:                           4                                         
Covariance Type:                  HC1                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept      14.1992      0.159     89.131      0.000      13.886      14.512
ln_livesp      -0.1605      0.041     -3.917      0.000      -0.241      -0.080
ln_kitsp       -0.2991      0.028    -10.500      0.000      -0.355      -0.243
ln_dist        -0.3303      0.024    -13.736      0.000      -0.377      -0.283
ln_metrdist    -0.0574      0.015     -3.937      0.000      -0.086      -0.029
==============================================================================
Omnibus:                       25.080   Durbin-Watson:                   1.309
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.855
Skew:                           0.425   Prob(JB):                     1.47e-06
Kurtosis:                       3.331   Cond. No.                         83.2
==============================================================================

Warnings:
[1] Standard Errors are heteroscedasticity robust (HC1)
&quot;&quot;&quot;</code></pre>
</div>
<div id="stata-4" class="section level2">
<h2><span class="header-section-number">7.3</span> stata</h2>
<p>Теперь попробуем поработать в <strong>stata</strong>.</p>
<p>Импортируем датасет для анализа.</p>
<pre class="stata"><code>use data/flats.dta</code></pre>
<pre><code>end of do-file</code></pre>
<p>Построим линейную регрессионную модель.</p>
<pre class="stata"><code>reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist</code></pre>
<pre><code>      Source |       SS           df       MS      Number of obs   =       773
-------------+----------------------------------   F(4, 768)       =    137.86
       Model |  29.3972704         4  7.34931759   Prob &gt; F        =    0.0000
    Residual |  40.9421359       768  .053310073   R-squared       =    0.4179
-------------+----------------------------------   Adj R-squared   =    0.4149
       Total |  70.3394063       772  .091113221   Root MSE        =    .23089

------------------------------------------------------------------------------
ln_price_~tr |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   ln_livesp |  -.1605276   .0372309    -4.31   0.000    -.2336141   -.0874411
    ln_kitsp |  -.2991296   .0229974   -13.01   0.000    -.3442748   -.2539843
     ln_dist |  -.3302511   .0236707   -13.95   0.000    -.3767181   -.2837841
 ln_metrdist |  -.0573754   .0155965    -3.68   0.000    -.0879923   -.0267585
       _cons |    14.1992   .1349184   105.24   0.000     13.93434    14.46405
------------------------------------------------------------------------------</code></pre>
<p>Визуализируем зависимость регрессоров и регрессанта.</p>
<pre class="stata"><code>scatter ln_price_metr ln_kitsp</code></pre>
<p><img src="kitsp.png" /></p>
<pre class="stata"><code>scatter ln_price_metr ln_livesp</code></pre>
<p><img src="livesp.png" /></p>
<pre class="stata"><code>scatter ln_price_metr ln_dist</code></pre>
<p><img src="dist.png" /></p>
<pre class="stata"><code>scatter ln_price_metr ln_metrdist</code></pre>
<p><img src="metrdist.png" /></p>
<p>Подозрительны переменные <code>ln_kitsp</code> и <code>ln_metrdist</code>
Проверим наличие гетероскедастичности с помощью тестов.</p>
<p>Тест Уайта строится по короткой команде:</p>
<pre class="stata"><code>estat imtest, white</code></pre>
<pre><code> translator Graph2png not found
r(111);



White&#39;s test for Ho: homoskedasticity
         against Ha: unrestricted heteroskedasticity

         chi2(14)     =     89.02
         Prob &gt; chi2  =    0.0000

Cameron &amp; Trivedi&#39;s decomposition of IM-test

---------------------------------------------------
              Source |       chi2     df      p
---------------------+-----------------------------
  Heteroskedasticity |      89.02     14    0.0000
            Skewness |      41.02      4    0.0000
            Kurtosis |       3.10      1    0.0785
---------------------+-----------------------------
               Total |     133.14     19    0.0000
---------------------------------------------------</code></pre>
<p>Тест Уайта выявил гетероскедастичность. Что скажет тест Бройша-Пагана?</p>
<pre class="stata"><code>estat hettest, rhs mtest</code></pre>
<pre><code> translator Graph2png not found
r(111);



Breusch-Pagan / Cook-Weisberg test for heteroskedasticity 
         Ho: Constant variance

---------------------------------------
    Variable |      chi2   df      p 
-------------+-------------------------
   ln_livesp |      0.00    1   0.9554 #
    ln_kitsp |      8.68    1   0.0032 #
     ln_dist |      1.43    1   0.2322 #
 ln_metrdist |      5.15    1   0.0233 #
-------------+-------------------------
simultaneous |     18.39    4   0.0010
---------------------------------------
                  # unadjusted p-values</code></pre>
<p>И этот тест указывает на наличие нежелательной гетероскедастичности, особенно подозрительны переменные <code>ln_kitsp</code> и <code>ln_metrdist</code>.</p>
<p>Попробуем проверить ещё и через тест Голдфелда - Квандта. Сделаем его ручками.</p>
<p>Отсортируем наблюдения по возрастанию переменной <code>ln_kitsp</code>, построим регрессию и сохраним остатки.</p>
<pre class="stata"><code>sort ln_kitsp
reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist in 1 / 258
scalar rss1 = e(rss)</code></pre>
<pre><code> translator Graph2png not found
r(111);

      Source |       SS           df       MS      Number of obs   =       258
-------------+----------------------------------   F(4, 253)       =    101.40
       Model |  21.2645968         4   5.3161492   Prob &gt; F        =    0.0000
    Residual |  13.2646645       253  .052429504   R-squared       =    0.6158
-------------+----------------------------------   Adj R-squared   =    0.6098
       Total |  34.5292613       257  .134355102   Root MSE        =    .22897

------------------------------------------------------------------------------
ln_price_~tr |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   ln_livesp |  -.2173122   .1051021    -2.07   0.040    -.4242986   -.0103257
    ln_kitsp |  -.6297139   .0524724   -12.00   0.000    -.7330522   -.5263756
     ln_dist |  -.3944732   .0447965    -8.81   0.000    -.4826947   -.3062517
 ln_metrdist |  -.0652324   .0289029    -2.26   0.025    -.1221534   -.0083114
       _cons |    15.0251   .2802776    53.61   0.000     14.47312    15.57707
------------------------------------------------------------------------------</code></pre>
<p>Сохраним остатки и в последней части регрессии.</p>
<pre class="stata"><code>sort ln_kitsp
reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist in 516 / 773
scalar rss2 = e(rss)</code></pre>
<pre><code> translator Graph2png not found
r(111);

      Source |       SS           df       MS      Number of obs   =       258
-------------+----------------------------------   F(4, 253)       =     21.08
       Model |  5.10171614         4  1.27542903   Prob &gt; F        =    0.0000
    Residual |  15.3095119       253  .060511905   R-squared       =    0.2499
-------------+----------------------------------   Adj R-squared   =    0.2381
       Total |  20.4112281       257  .079421121   Root MSE        =    .24599

------------------------------------------------------------------------------
ln_price_~tr |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   ln_livesp |  -.1140016   .0622764    -1.83   0.068    -.2366478    .0086446
    ln_kitsp |   .0358976   .0958643     0.37   0.708    -.1528962    .2246914
     ln_dist |  -.3344044   .0428089    -7.81   0.000    -.4187116   -.2500972
 ln_metrdist |  -.0757551   .0285959    -2.65   0.009    -.1320714   -.0194388
       _cons |   13.36548   .3551862    37.63   0.000     12.66598    14.06498
------------------------------------------------------------------------------</code></pre>
<p>Посчитаем тестовую F-статистику.</p>
<pre class="stata"><code>scalar F = rss2 / rss1
display F
display invFtail(258, 258, 0.05)</code></pre>
<pre><code> translator Graph2png not found
r(111);


rss2 not found
r(111);

end of do-file
r(111);</code></pre>
<p>Тестовая статистика больше табличной, следовательно, гетероскедастичность присутствует.</p>
<p>Сейчас немного о способах борьбы с гетероскедастичностью. Подправим все коэффициенты исходной регрессии на гетероскедастичную переменную, например, на <code>ln_kitsp</code>.</p>
<pre class="stata"><code>gen ln_price_metr_new = ln_price_metr / ln_kitsp
gen ln_livesp_new = ln_livesp / ln_kitsp
gen const_new = 1 / ln_kitsp
gen ln_dist_new = ln_dist / ln_kitsp
gen ln_metrdist_new = ln_metrdist / ln_kitsp</code></pre>
<pre><code> translator Graph2png not found
r(111);
</code></pre>
<p>И оценим регрессию с новыми переменными.</p>
<pre class="stata"><code>reg ln_price_metr_new ln_livesp_new const_new ln_dist_new ln_metrdist_new</code></pre>
<pre><code> translator Graph2png not found
r(111);


variable ln_price_metr_new not found
r(111);

end of do-file
r(111);</code></pre>
<p>И полученные оценки будут эффективными оценками коэффициентов исходной регрессии.</p>
<p>Также можно использовать метод взвешенного МНК (WLS). Взвесим на стандартное отклонение фактора <code>ln_kitsp</code>.</p>
<pre class="stata"><code>vwls ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist, sd(ln_kitsp)</code></pre>
<pre><code> translator Graph2png not found
r(111);



Variance-weighted least-squares regression      Number of obs     =        773
Goodness-of-fit chi2(768)  =   13.89            Model chi2(4)     =      23.60
Prob &gt; chi2                =  1.0000            Prob &gt; chi2       =     0.0001
------------------------------------------------------------------------------
ln_price_~tr |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   ln_livesp |  -.1844788   .3304308    -0.56   0.577    -.8321113    .4631537
    ln_kitsp |  -.4051277   .1586073    -2.55   0.011    -.7159924   -.0942631
     ln_dist |  -.3401236   .1892387    -1.80   0.072    -.7110247    .0307775
 ln_metrdist |  -.0738144   .1320896    -0.56   0.576    -.3327052    .1850765
       _cons |   14.53768   1.051168    13.83   0.000     12.47743    16.59793
------------------------------------------------------------------------------</code></pre>
<p>Способ #2. Используем робастные оценки Уайта.</p>
<pre class="stata"><code>reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist, robust</code></pre>
<pre><code> translator Graph2png not found
r(111);



Linear regression                               Number of obs     =        773
                                                F(4, 768)         =     102.52
                                                Prob &gt; F          =     0.0000
                                                R-squared         =     0.4179
                                                Root MSE          =     .23089

------------------------------------------------------------------------------
             |               Robust
ln_price_~tr |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   ln_livesp |  -.1605276   .0409773    -3.92   0.000    -.2409685   -.0800867
    ln_kitsp |  -.2991296   .0284899   -10.50   0.000    -.3550568   -.2432023
     ln_dist |  -.3302511   .0240433   -13.74   0.000    -.3774495   -.2830527
 ln_metrdist |  -.0573754   .0145748    -3.94   0.000    -.0859867   -.0287642
       _cons |    14.1992   .1593064    89.13   0.000     13.88647    14.51192
------------------------------------------------------------------------------</code></pre>
<p>Робастные оценки Уайта позволяют снизить последствия гетероскедастичности через уменьшение стандартных ошибок коэффициентов регрессии.</p>

</div>
<div id="pca" class="section level2">
<h2><span class="header-section-number">7.4</span> # Коан о методе главных компонент</h2>
<style>
pre.r {
    background-color: #FEF9E7 !important;
}
pre.stata {
    background-color: #BDBDBD !important;
}
pre.python {
    background-color: #FDF2E9 !important;
}
</style>
<blockquote>
<p>Метод главных компонент позволяет снизить размерность данных за счет замены исходных переменных на меньшее количество новых переменных. Новые, искусственно созданные, переменные называются главными компонентами.</p>
</blockquote>
<p>Реализация метода главных компонент “вручную” включает в себя следующие элементы:</p>
<ol style="list-style-type: decimal">
<li>Центрирование исходных данных</li>
<li>Вычисление собственных значений матрицы <span class="math inline">\(X^TX\)</span></li>
<li>Расчет доли дисперсии, объясняемой найденными компонентами</li>
<li>Выбор числа главных компонент</li>
</ol>
<p>Однако прогресс не стоит на месте, и получение главных компонент теперь осуществляется быстрее и проще (а главное совершенно бесплатно и без регистрации). Рассмотрим, как проделать это на r, python и в stata.</p>
</div>
<div id="r-5" class="section level2">
<h2><span class="header-section-number">7.5</span> r</h2>
<p>Загружаем нужные пакеты:</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb446-1" data-line-number="1"><span class="kw">library</span>(dplyr) <span class="co"># Для работы с данными</span></a>
<a class="sourceLine" id="cb446-2" data-line-number="2"><span class="kw">library</span>(ggplot2) <span class="co"># Для построения графиков</span></a>
<a class="sourceLine" id="cb446-3" data-line-number="3"><span class="kw">library</span>(skimr) <span class="co"># Для изучения данных</span></a>
<a class="sourceLine" id="cb446-4" data-line-number="4"><span class="kw">library</span>(FactoMineR) <span class="co"># Для анализа</span></a>
<a class="sourceLine" id="cb446-5" data-line-number="5"><span class="kw">library</span>(factoextra) <span class="co"># Для визуализации главных компонент </span></a></code></pre></div>
<p>Загружаем набор данных по параметрам машин <strong>mtcars</strong> и изучаем его строение:</p>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb447-1" data-line-number="1"><span class="kw">skim</span>(mtcars)</a></code></pre></div>
<pre><code>Skim summary statistics
 n obs: 32 
 n variables: 11 

── Variable type:numeric ─────────────────────────────────────────────────────────────────────────────────────────────────────────
 variable missing complete  n   mean     sd    p0    p25    p50    p75
       am       0       32 32   0.41   0.5   0      0      0      1   
     carb       0       32 32   2.81   1.62  1      2      2      4   
      cyl       0       32 32   6.19   1.79  4      4      6      8   
     disp       0       32 32 230.72 123.94 71.1  120.83 196.3  326   
     drat       0       32 32   3.6    0.53  2.76   3.08   3.7    3.92
     gear       0       32 32   3.69   0.74  3      3      4      4   
       hp       0       32 32 146.69  68.56 52     96.5  123    180   
      mpg       0       32 32  20.09   6.03 10.4   15.43  19.2   22.8 
     qsec       0       32 32  17.85   1.79 14.5   16.89  17.71  18.9 
       vs       0       32 32   0.44   0.5   0      0      0      1   
       wt       0       32 32   3.22   0.98  1.51   2.58   3.33   3.61
   p100     hist
   1    ▇▁▁▁▁▁▁▆
   8    ▆▇▂▇▁▁▁▁
   8    ▆▁▁▃▁▁▁▇
 472    ▇▆▁▂▅▃▁▂
   4.93 ▃▇▁▅▇▂▁▁
   5    ▇▁▁▆▁▁▁▂
 335    ▃▇▃▅▂▃▁▁
  33.9  ▃▇▇▇▃▂▂▂
  22.9  ▃▂▇▆▃▃▁▁
   1    ▇▁▁▁▁▁▁▆
   5.42 ▃▃▃▇▆▁▁▂</code></pre>
<p>Целевая переменная в данном наборе данных - это <code>mpg</code>, miles per gallon. Для МГК нам понадобится произвести стандартизацию регрессоров, так как разные переменные измерены в несопоставимых единицах измерения:</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb449-1" data-line-number="1">c =<span class="st"> </span><span class="kw">select</span>(mtcars, <span class="op">-</span>mpg) <span class="co"># Выделяем регрессоры в отдельный список</span></a>
<a class="sourceLine" id="cb449-2" data-line-number="2">c_pca =<span class="st"> </span><span class="kw">PCA</span>(c, <span class="dt">scale.unit =</span> <span class="ot">TRUE</span>, <span class="dt">graph =</span> <span class="ot">FALSE</span>) <span class="co"># Применяем функцию PCA для нахождения главных компонент, при этом проводим стандартизацию (scale.unit=TRUE)</span></a></code></pre></div>
<p>Используя возможности пакета <strong>factoextra</strong>, построим несколько графиков, чтобы иметь полное представление о созданных главных компонентах. Для начала визуализируем долю объясняемой главными компонентами дисперсии с помощью функции <em>fviz_eig</em>:</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb450-1" data-line-number="1"><span class="kw">fviz_eig</span>(c_pca, <span class="dt">addlabels =</span> <span class="ot">TRUE</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">65</span>), <span class="dt">barfill =</span> <span class="st">&quot;dodgerblue2&quot;</span>, <span class="dt">barcolor =</span> <span class="st">&quot;dodgerblue4&quot;</span>, <span class="dt">linecolor =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Доля объясняемой дисперсии&quot;</span>)</a></code></pre></div>
<p><img src="11-pca_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Итак, две первые главные компоненты, PC1 и PC2, объясняют более 85% дисперсии.</p>
<p>Посмотрим, в каких переменных содержится больше всего информации, т.е. какие из них вносят наибольший вклад в объяснение дисперсии, с помощью функции <em>fviz_contrib</em>.</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb451-1" data-line-number="1"><span class="kw">fviz_contrib</span>(c_pca, <span class="dt">choice =</span> <span class="st">&quot;var&quot;</span>, <span class="dt">axes =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dt">top =</span> <span class="dv">10</span>, <span class="dt">fill =</span> <span class="st">&quot;darkseagreen2&quot;</span>, <span class="dt">linecolor =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Вклад переменных в первую и вторую главные компоненты&quot;</span>)</a></code></pre></div>
<p><img src="11-pca_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Соответственно, наибольшая информация содержится в переменных <code>cyl</code>, <code>disp</code>, <code>qsec</code>.</p>
<p>Построим так называемый <strong>Correlation Circle</strong>, показывающий корреляцию между исходными переменными и главными компонентами, используя функцию <em>fviz_pca_var</em>. Покажем вклад переменных в первую и вторую главные компоненты цветом:</p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb452-1" data-line-number="1"><span class="kw">fviz_pca_var</span>(c_pca, <span class="dt">col.var =</span> <span class="st">&quot;contrib&quot;</span>,</a>
<a class="sourceLine" id="cb452-2" data-line-number="2">             <span class="dt">gradient.cols =</span> <span class="kw">c</span>(<span class="st">&quot;#00AFBB&quot;</span>, <span class="st">&quot;#E7B800&quot;</span>, <span class="st">&quot;#FC4E07&quot;</span>),</a>
<a class="sourceLine" id="cb452-3" data-line-number="3">             <span class="dt">title =</span> <span class="st">&quot;Корреляция между исходными переменными и главными компонентами&quot;</span>)</a></code></pre></div>
<p><img src="11-pca_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Переменные с положительной корреляцией расположены близко друг к другу (например, <code>cyl</code> и <code>hp</code>), с отрицательной корреляцией - на противоположных частях графика (<code>drat</code> и <code>wt</code>). Чем больше дистанция между переменными и началом координат, тем лучше их удается описать при помощи главных компонент.</p>
</div>
<div id="stata-5" class="section level2">
<h2><span class="header-section-number">7.6</span> stata</h2>
<p>Загружаем нужные нам данные, в данном случае сведения об автомобилях, содержащиеся в пакете auto.</p>
<pre class="stata"><code>webuse auto</code></pre>
<pre><code></code></pre>
<p>Для реализации МГК достаточно использовать функцию <code>pca</code>. Она принимает на вход зависимую переменную <code>price</code> и регрессоры <code>mpg</code>, <code>rep78</code>, <code>headroom</code>, <code>weight</code>, <code>length</code>, <code>displacement</code>, <code>foreign</code>:</p>
<pre class="stata"><code>pca price mpg rep78 headroom weight length displacement foreign</code></pre>
<pre><code>Principal components/correlation                 Number of obs    =         69
                                                 Number of comp.  =          8
                                                 Trace            =          8
    Rotation: (unrotated = principal)            Rho              =     1.0000

    --------------------------------------------------------------------------
       Component |   Eigenvalue   Difference         Proportion   Cumulative
    -------------+------------------------------------------------------------
           Comp1 |       4.7823      3.51481             0.5978       0.5978
           Comp2 |       1.2675      .429638             0.1584       0.7562
           Comp3 |      .837857      .398188             0.1047       0.8610
           Comp4 |      .439668     .0670301             0.0550       0.9159
           Comp5 |      .372638      .210794             0.0466       0.9625
           Comp6 |      .161844     .0521133             0.0202       0.9827
           Comp7 |      .109731      .081265             0.0137       0.9964
           Comp8 |     .0284659            .             0.0036       1.0000
    --------------------------------------------------------------------------

Principal components (eigenvectors) 

    --------------------------------------------------------------------------
        Variable |    Comp1     Comp2     Comp3     Comp4     Comp5     Comp6 
    -------------+------------------------------------------------------------
           price |   0.2324    0.6397   -0.3334   -0.2099    0.4974   -0.2815 
             mpg |  -0.3897   -0.1065    0.0824    0.2568    0.6975    0.5011 
           rep78 |  -0.2368    0.5697    0.3960    0.6256   -0.1650   -0.1928 
        headroom |   0.2560   -0.0315    0.8439   -0.3750    0.2560   -0.1184 
          weight |   0.4435    0.0979   -0.0325    0.1792   -0.0296    0.2657 
          length |   0.4298    0.0687    0.0864    0.1845   -0.2438    0.4144 
    displacement |   0.4304    0.0851   -0.0445    0.1524    0.1782    0.2907 
         foreign |  -0.3254    0.4820    0.0498   -0.5183   -0.2850    0.5401 
    --------------------------------------------------------------------------

    ------------------------------------------------
        Variable |    Comp7     Comp8 | Unexplained 
    -------------+--------------------+-------------
           price |   0.2165   -0.0891 |           0 
             mpg |   0.1625    0.0115 |           0 
           rep78 |  -0.0813    0.0065 |           0 
        headroom |   0.0226    0.0252 |           0 
          weight |   0.1104    0.8228 |           0 
          length |   0.5437   -0.4921 |           0 
    displacement |  -0.7733   -0.2608 |           0 
         foreign |  -0.1173    0.0639 |           0 
    ------------------------------------------------</code></pre>
<p>Построим график доли дисперсии, объясняемой каждой компонентой:</p>
<pre class="stata"><code>screeplot, yline(1) ci(het) </code></pre>
<p><img src="scr.png" /></p>
<p>И получим первые две компоненты:</p>
<pre class="stata"><code>predict pc1 pc2, score</code></pre>
<pre><code> translator Graph2png not found
r(111);


(6 components skipped)

Scoring coefficients 
    sum of squares(column-loading) = 1

    --------------------------------------------------------------------------
        Variable |    Comp1     Comp2     Comp3     Comp4     Comp5     Comp6 
    -------------+------------------------------------------------------------
           price |   0.2324    0.6397   -0.3334   -0.2099    0.4974   -0.2815 
             mpg |  -0.3897   -0.1065    0.0824    0.2568    0.6975    0.5011 
           rep78 |  -0.2368    0.5697    0.3960    0.6256   -0.1650   -0.1928 
        headroom |   0.2560   -0.0315    0.8439   -0.3750    0.2560   -0.1184 
          weight |   0.4435    0.0979   -0.0325    0.1792   -0.0296    0.2657 
          length |   0.4298    0.0687    0.0864    0.1845   -0.2438    0.4144 
    displacement |   0.4304    0.0851   -0.0445    0.1524    0.1782    0.2907 
         foreign |  -0.3254    0.4820    0.0498   -0.5183   -0.2850    0.5401 
    --------------------------------------------------------------------------

    ----------------------------------
        Variable |    Comp7     Comp8 
    -------------+--------------------
           price |   0.2165   -0.0891 
             mpg |   0.1625    0.0115 
           rep78 |  -0.0813    0.0065 
        headroom |   0.0226    0.0252 
          weight |   0.1104    0.8228 
          length |   0.5437   -0.4921 
    displacement |  -0.7733   -0.2608 
         foreign |  -0.1173    0.0639 
    ----------------------------------</code></pre>
</div>
<div id="python-5" class="section level2">
<h2><span class="header-section-number">7.7</span> python</h2>
<p>Начинаем, как обычно, с обработки данных. Загружаем необходимые для работы библиотеки</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb460-1" data-line-number="1"><span class="im">import</span> pandas <span class="im">as</span> pd <span class="co"># Библиотека pandas для работы с данными</span></a>
<a class="sourceLine" id="cb460-2" data-line-number="2"><span class="im">import</span> seaborn <span class="im">as</span> sns <span class="co"># Библиотека seaborn для визуализации</span></a>
<a class="sourceLine" id="cb460-3" data-line-number="3"><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA <span class="co"># Импортируем функцию PCA, вычисляющую главные компоненты</span></a>
<a class="sourceLine" id="cb460-4" data-line-number="4"><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler <span class="co"># Импортируем StandartScaler</span></a></code></pre></div>
<p>и набор данных <em>auto mpg dataset</em>:</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb461-1" data-line-number="1">url <span class="op">=</span> <span class="st">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original&quot;</span></a>
<a class="sourceLine" id="cb461-2" data-line-number="2">df <span class="op">=</span> pd.read_csv(url, </a>
<a class="sourceLine" id="cb461-3" data-line-number="3">                delim_whitespace <span class="op">=</span> <span class="va">True</span>, </a>
<a class="sourceLine" id="cb461-4" data-line-number="4">                header<span class="op">=</span><span class="va">None</span>,</a>
<a class="sourceLine" id="cb461-5" data-line-number="5">                names <span class="op">=</span> [<span class="st">&#39;mpg&#39;</span>, <span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;displacement&#39;</span>,         <span class="st">&#39;horsepower&#39;</span>, <span class="st">&#39;weight&#39;</span>, <span class="st">&#39;acceleration&#39;</span>, <span class="st">&#39;model&#39;</span>, <span class="st">&#39;origin&#39;</span>, <span class="st">&#39;car_name&#39;</span>])  </a></code></pre></div>
<p>Изучим строение данных:</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb462-1" data-line-number="1">df.head()</a></code></pre></div>
<pre><code>    mpg  cylinders  displacement  ...  model  origin                   car_name
0  18.0        8.0         307.0  ...   70.0     1.0  chevrolet chevelle malibu
1  15.0        8.0         350.0  ...   70.0     1.0          buick skylark 320
2  18.0        8.0         318.0  ...   70.0     1.0         plymouth satellite
3  16.0        8.0         304.0  ...   70.0     1.0              amc rebel sst
4  17.0        8.0         302.0  ...   70.0     1.0                ford torino

[5 rows x 9 columns]</code></pre>
<p>Так как в наших данных, кроме прочего, также присутствуют и другие типы переменных (например, содержащиеся в переменной <code>car_names</code> названия машин), то предварительно очистим данные, оставив только численные переменные. После этого используем функцию StandartScaler для стандартизации регрессоров:</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb464-1" data-line-number="1">df <span class="op">=</span> df.dropna() <span class="co"># Убираем пропущенные значения (NAs)</span></a>
<a class="sourceLine" id="cb464-2" data-line-number="2">features <span class="op">=</span> [<span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;displacement&#39;</span>, <span class="st">&#39;horsepower&#39;</span>, <span class="st">&#39;weight&#39;</span>, <span class="st">&#39;acceleration&#39;</span>, <span class="st">&#39;origin&#39;</span>] <span class="co"># Добавляем количественные регрессоры в отдельный список, убираем переменные car_names, model</span></a>
<a class="sourceLine" id="cb464-3" data-line-number="3">x <span class="op">=</span> df[features] <span class="co"># Выделяем численные значения регрессоров !!!Упростить!!!</span></a>
<a class="sourceLine" id="cb464-4" data-line-number="4">y <span class="op">=</span> df[<span class="st">&#39;mpg&#39;</span>] <span class="co"># Выделяем целевую переменную</span></a>
<a class="sourceLine" id="cb464-5" data-line-number="5">x <span class="op">=</span> StandardScaler().fit_transform(x) <span class="co"># Стандартизируем регрессоры</span></a></code></pre></div>
<p>Создадим три главные компоненты:</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb465-1" data-line-number="1">pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>) <span class="co"># Создаем 3 главные компоненты</span></a>
<a class="sourceLine" id="cb465-2" data-line-number="2">principalComponents <span class="op">=</span> pca.fit_transform(x)</a>
<a class="sourceLine" id="cb465-3" data-line-number="3">principalDf <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> principalComponents, columns <span class="op">=</span> [<span class="st">&#39;principal component 1&#39;</span>, <span class="st">&#39;principal component 2&#39;</span>, <span class="st">&#39;principal component 3&#39;</span>]) <span class="co"># Создаем таблицу, в которую сохраняем значения найденных компонент</span></a></code></pre></div>
<p>Вычислим, какую долю дисперсии объясняют главные компоненты:</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb466-1" data-line-number="1">pca.explained_variance_ratio_</a></code></pre></div>
<pre><code>array([0.73960122, 0.14245627, 0.08026557])</code></pre>
<p>Таким образом, три главные компоненты объясняют примерно 74 + 14 + 1 = 89% дисперсии.
Представим это на графике:</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb468-1" data-line-number="1">df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;var&#39;</span>:pca.explained_variance_ratio_, <span class="st">&#39;PC&#39;</span>:[<span class="st">&#39;PC1&#39;</span>, <span class="st">&#39;PC2&#39;</span>, <span class="st">&#39;PC3&#39;</span>]})</a>
<a class="sourceLine" id="cb468-2" data-line-number="2">graph <span class="op">=</span> sns.barplot(x <span class="op">=</span> <span class="st">&#39;PC&#39;</span>, y <span class="op">=</span> <span class="st">&#39;var&#39;</span>, data <span class="op">=</span> df, color <span class="op">=</span> <span class="st">&#39;wheat&#39;</span>)</a>
<a class="sourceLine" id="cb468-3" data-line-number="3">graph.set_title(<span class="st">&quot;Доля дисперсии, объясняемой главными компонентами&quot;</span>)</a>
<a class="sourceLine" id="cb468-4" data-line-number="4">graph.set_ylabel(<span class="st">&#39;Доля дисперсии&#39;</span>)</a>
<a class="sourceLine" id="cb468-5" data-line-number="5">graph.set_xlabel(<span class="st">&#39;Главные компоненты&#39;</span>)</a></code></pre></div>
<p><img src="11-pca_files/figure-html/unnamed-chunk-17-1.png" width="672" />
```</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="paneldata.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dinpanel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Rosetta_Stone.pdf", "Rosetta_Stone.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
