<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Коан 3 Коан о простой линейной регрессии | Розеттский камень</title>
  <meta name="description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Коан 3 Коан о простой линейной регрессии | Розеттский камень" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Коан 3 Коан о простой линейной регрессии | Розеттский камень" />
  
  <meta name="twitter:description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  

<meta name="author" content="Пуассон, фея и три мексиканских негодяя" />


<meta name="date" content="2019-09-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="installsoft.html"/>
<link rel="next" href="poisreg.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Напутственное слово</a></li>
<li class="chapter" data-level="2" data-path="installsoft.html"><a href="installsoft.html"><i class="fa fa-check"></i><b>2</b> Коан об установке софта</a></li>
<li class="chapter" data-level="3" data-path="simplereg.html"><a href="simplereg.html"><i class="fa fa-check"></i><b>3</b> Коан о простой линейной регрессии</a><ul>
<li class="chapter" data-level="3.1" data-path="simplereg.html"><a href="simplereg.html#r"><i class="fa fa-check"></i><b>3.1</b> r</a></li>
<li class="chapter" data-level="3.2" data-path="simplereg.html"><a href="simplereg.html#python"><i class="fa fa-check"></i><b>3.2</b> python</a></li>
<li class="chapter" data-level="3.3" data-path="simplereg.html"><a href="simplereg.html#stata"><i class="fa fa-check"></i><b>3.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="poisreg.html"><a href="poisreg.html"><i class="fa fa-check"></i><b>4</b> Модели счетных данных</a><ul>
<li class="chapter" data-level="4.1" data-path="poisreg.html"><a href="poisreg.html#r-1"><i class="fa fa-check"></i><b>4.1</b> r</a></li>
<li class="chapter" data-level="4.2" data-path="poisreg.html"><a href="poisreg.html#python-1"><i class="fa fa-check"></i><b>4.2</b> python</a></li>
<li class="chapter" data-level="4.3" data-path="poisreg.html"><a href="poisreg.html#stata-1"><i class="fa fa-check"></i><b>4.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="disordered.html"><a href="disordered.html"><i class="fa fa-check"></i><b>5</b> Модели неупорядоченного выбора</a></li>
<li class="chapter" data-level="6" data-path="instruments.html"><a href="instruments.html"><i class="fa fa-check"></i><b>6</b> Интcтрументы для простой регрессии</a></li>
<li class="chapter" data-level="7" data-path="arma.html"><a href="arma.html"><i class="fa fa-check"></i><b>7</b> ARMA</a><ul>
<li class="chapter" data-level="7.1" data-path="arma.html"><a href="arma.html#r-2"><i class="fa fa-check"></i><b>7.1</b> r</a></li>
<li class="chapter" data-level="7.2" data-path="arma.html"><a href="arma.html#python-2"><i class="fa fa-check"></i><b>7.2</b> python</a></li>
<li class="chapter" data-level="7.3" data-path="arma.html"><a href="arma.html#stata-2"><i class="fa fa-check"></i><b>7.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="paneldata.html"><a href="paneldata.html"><i class="fa fa-check"></i><b>8</b> Панельные данные</a></li>
<li class="chapter" data-level="9" data-path="heterosked.html"><a href="heterosked.html"><i class="fa fa-check"></i><b>9</b> Гетероскедастичность в простой регрессии</a><ul>
<li class="chapter" data-level="9.1" data-path="heterosked.html"><a href="heterosked.html#r-3"><i class="fa fa-check"></i><b>9.1</b> r</a></li>
<li class="chapter" data-level="9.2" data-path="heterosked.html"><a href="heterosked.html#python-3"><i class="fa fa-check"></i><b>9.2</b> python</a></li>
<li class="chapter" data-level="9.3" data-path="heterosked.html"><a href="heterosked.html#stata-3"><i class="fa fa-check"></i><b>9.3</b> stata</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>10</b> PCA</a></li>
<li class="chapter" data-level="11" data-path="dinpanel.html"><a href="dinpanel.html"><i class="fa fa-check"></i><b>11</b> Динамические панели</a></li>
<li class="chapter" data-level="12" data-path="tobit-heckit.html"><a href="tobit-heckit.html"><i class="fa fa-check"></i><b>12</b> TOBIT, HECKIT</a></li>
<li class="chapter" data-level="13" data-path="treatment.html"><a href="treatment.html"><i class="fa fa-check"></i><b>13</b> Treatment effect</a></li>
<li class="chapter" data-level="14" data-path="compatability.html"><a href="compatability.html"><i class="fa fa-check"></i><b>14</b> Что-то там про совместимость и языки</a></li>
<li class="chapter" data-level="15" data-path="dict.html"><a href="dict.html"><i class="fa fa-check"></i><b>15</b> Словарь</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Розеттский камень</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simplereg" class="section level1">
<h1><span class="header-section-number">Коан 3</span> Коан о простой линейной регрессии</h1>
<div id="r" class="section level2">
<h2><span class="header-section-number">3.1</span> r</h2>
<p>Построим простую линейную регрессию в R и проведем несложные тесты.</p>
<p>Загрузим необходимые пакеты.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(tidyverse) <span class="co"># для манипуляций с данными и построения графиков</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(skimr) <span class="co"># для красивого summary</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">library</span>(rio) <span class="co"># для чтения .dta файлов</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">library</span>(car) <span class="co"># для линейных гипотез</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="kw">library</span>(tseries) <span class="co"># для теста на нормальность</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw">library</span>(sjPlot) <span class="co"># еще графики</span></a></code></pre></div>
<p>Импортируем данные.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">df =<span class="st"> </span>rio<span class="op">::</span><span class="kw">import</span>(<span class="st">&quot;data/us-return.dta&quot;</span>)</a></code></pre></div>
<p>Исследуем наш датасет.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">skim_with</span>(<span class="dt">numeric =</span> <span class="kw">list</span>(<span class="dt">hist =</span> <span class="ot">NULL</span>, <span class="dt">p25 =</span> <span class="ot">NULL</span>, <span class="dt">p75 =</span> <span class="ot">NULL</span>)) <span class="co"># опустим некоторые описательные статистики</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">skim</span>(df) </a></code></pre></div>
<pre><code>Skim summary statistics
 n obs: 2664 
 n variables: 22 

── Variable type:character ─────────────────────────────────────────────────────────────────
 variable missing complete    n min max empty n_unique
        B       0     2664 2664   0   6  2544       31

── Variable type:numeric ───────────────────────────────────────────────────────────────────
 variable missing complete    n    mean      sd      p0     p50    p100
        A    2544      120 2664 60.5    34.79    1      60.5    120    
    BOISE    2544      120 2664  0.017   0.097  -0.27    0.015    0.38 
   CITCRP    2544      120 2664  0.012   0.081  -0.28    0.011    0.32 
    CONED    2544      120 2664  0.019   0.05   -0.14    0.019    0.15 
   CONTIL    2544      120 2664 -0.0011  0.15   -0.6     0        0.97 
   DATGEN    2544      120 2664  0.0075  0.13   -0.34    0.017    0.53 
      DEC    2544      120 2664  0.02    0.099  -0.36    0.024    0.39 
    DELTA    2544      120 2664  0.012   0.096  -0.26    0.013    0.29 
   GENMIL    2544      120 2664  0.017   0.065  -0.15    0.011    0.19 
   GERBER    2544      120 2664  0.016   0.088  -0.29    0.015    0.23 
      IBM    2544      120 2664  0.0096  0.059  -0.19    0.002    0.15 
   MARKET    2544      120 2664  0.014   0.068  -0.26    0.012    0.15 
    MOBIL    2544      120 2664  0.016   0.08   -0.18    0.013    0.37 
    MOTOR    2544      120 2664  0.018   0.097  -0.33    0.017    0.27 
    PANAM    2544      120 2664  0.0035  0.13   -0.31    0        0.41 
     PSNH    2544      120 2664 -0.0042  0.11   -0.48    0        0.32 
   rkfree    2544      120 2664  0.0068  0.0022  0.0021  0.0066   0.013
   RKFREE    2544      120 2664  0.0068  0.0022  0.0021  0.0066   0.013
    TANDY    2544      120 2664  0.025   0.13   -0.25    0.022    0.45 
   TEXACO    2544      120 2664  0.012   0.08   -0.19    0.01     0.4  
    WEYER    2544      120 2664  0.0096  0.085  -0.27   -0.002    0.27 </code></pre>
<p>Переименуем столбцы.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">df =<span class="st"> </span><span class="kw">rename</span>(df, <span class="dt">n =</span> A, <span class="dt">date =</span> B) </a></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">df =<span class="st"> </span><span class="kw">na.omit</span>(df) <span class="co"># уберем пустые строки</span></a></code></pre></div>
<p>Будем верить в CAPM :) Оценим параметры модели для компании MOTOR. Соответственно, зависимая переменная - разница доходностей акций MOTOR и безрискового актива, а регрессор - рыночная премия.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">df =<span class="st"> </span><span class="kw">mutate</span>(df, <span class="dt">y =</span> MOTOR <span class="op">-</span><span class="st"> </span>RKFREE, <span class="dt">x =</span> MARKET <span class="op">-</span><span class="st"> </span>RKFREE) </a></code></pre></div>
<p>Строим нашу модель и проверяем гипотезу об адекватности регрессии.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">ols =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> df)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="kw">summary</span>(ols)</a></code></pre></div>
<pre><code>
Call:
lm(formula = y ~ x, data = df)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.168421 -0.059381 -0.003399  0.061373  0.182991 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.005253   0.007200   0.730    0.467    
x           0.848150   0.104814   8.092 5.91e-13 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.07844 on 118 degrees of freedom
Multiple R-squared:  0.3569,    Adjusted R-squared:  0.3514 
F-statistic: 65.48 on 1 and 118 DF,  p-value: 5.913e-13</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">coeff =<span class="st"> </span><span class="kw">summary</span>(ols)<span class="op">$</span>coeff <span class="co"># отдельно табличка с коэффициентами</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2">coeff</a></code></pre></div>
<pre><code>               Estimate  Std. Error   t value     Pr(&gt;|t|)
(Intercept) 0.005252865 0.007199935 0.7295713 4.670981e-01
x           0.848149581 0.104813757 8.0919681 5.913330e-13</code></pre>
<p>Вызовом одной функции получаем кучу полезных графиков. Можем визуально оценить наличие гетероскедастичности, нормальность распределения остатков, наличие выбросов.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">plot</span>(ols)</a></code></pre></div>
<p><img src="02-simplereg_files/figure-html/plot-1.png" width="672" /><img src="02-simplereg_files/figure-html/plot-2.png" width="672" /><img src="02-simplereg_files/figure-html/plot-3.png" width="672" /><img src="02-simplereg_files/figure-html/plot-4.png" width="672" /></p>
<p>Строим доверительный интервал для параметров модели.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">est =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">Estimate =</span> <span class="kw">coef</span>(ols), <span class="kw">confint</span>(ols))</a></code></pre></div>
<p>Проверим гипотезу о равенстве коэффициента при регрессоре единице.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">linearHypothesis</span>(ols, <span class="kw">c</span>(<span class="st">&quot;x = 1&quot;</span>))</a></code></pre></div>
<pre><code>Linear hypothesis test

Hypothesis:
x = 1

Model 1: restricted model
Model 2: y ~ x

  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1    119 0.73900                           
2    118 0.72608  1  0.012915 2.0989 0.1501</code></pre>
<p>Посмотрим на остатки :) Протестируем остатки регрессии на нормальность с помощью теста Харке-Бера.</p>
<p><span class="math display">\[H_{0}: S = 0, K = 3,\\
\text{где S — коэффициент асимметрии (Skewness), K — коэффициент эксцесса (Kurtosis)}\]</span></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">jarque.bera.test</span>(<span class="kw">resid</span>(ols)) </a></code></pre></div>
<pre><code>
    Jarque Bera Test

data:  resid(ols)
X-squared = 1.7803, df = 2, p-value = 0.4106</code></pre>
<p>И тест Шапиро-Уилка.</p>
<p><span class="math inline">\(H_{0}: \epsilon_{i} \sim N(\mu,\sigma^2)\)</span></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">shapiro.test</span>(<span class="kw">resid</span>(ols))</a></code></pre></div>
<pre><code>
    Shapiro-Wilk normality test

data:  resid(ols)
W = 0.99021, p-value = 0.5531</code></pre>
<p>Оба теста указывают на нормальность распределения остатков регрессии.</p>
<p>Сделаем прогноз модели по данным вне обучаемой выборки.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">7</span>)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"></a>
<a class="sourceLine" id="cb20-3" data-line-number="3">newData =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> df<span class="op">$</span>x <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span><span class="kw">rnorm</span>(<span class="kw">length</span>(df<span class="op">$</span>x))) <span class="co">#пошумим</span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">yhat =<span class="st"> </span><span class="kw">predict</span>(ols, <span class="dt">newdata =</span> newData, <span class="dt">se =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
</div>
<div id="python" class="section level2">
<h2><span class="header-section-number">3.2</span> python</h2>
<p>Много полезных функций для статистических расчетов можно найти в пакете Statsmodels.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb21-1" data-line-number="1"></a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="im">import</span> pandas <span class="im">as</span> pd <span class="co"># для работы с таблицами</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;pandas&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np <span class="co"># математика, работа с матрицами</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt <span class="co"># графики</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;matplotlib&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;statsmodels&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;statsmodels&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="im">import</span> statsmodels.graphics.gofplots <span class="im">as</span> gf</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;statsmodels&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> summary_table</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;statsmodels&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="im">import</span> seaborn <span class="im">as</span> sns <span class="co"># еще более классные графики</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;seaborn&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="im">from</span> scipy.stats <span class="im">import</span> shapiro <span class="co"># еще математика</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;scipy&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb37-1" data-line-number="1"><span class="im">import</span> statsmodels.discrete.discrete_model</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;statsmodels&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>При желании, можем кастомизировать графики :)</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb39-1" data-line-number="1">plt.style.use(<span class="st">&#39;seaborn&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb41-1" data-line-number="1">plt.rc(<span class="st">&#39;font&#39;</span>, size<span class="op">=</span><span class="dv">14</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb43-1" data-line-number="1">plt.rc(<span class="st">&#39;figure&#39;</span>, titlesize<span class="op">=</span><span class="dv">15</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb45-1" data-line-number="1">plt.rc(<span class="st">&#39;axes&#39;</span>, labelsize<span class="op">=</span><span class="dv">15</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb47-1" data-line-number="1">plt.rc(<span class="st">&#39;axes&#39;</span>, titlesize<span class="op">=</span><span class="dv">15</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Загрузим данные.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb49-1" data-line-number="1">df <span class="op">=</span> pd.read_stata(<span class="st">&#39;data/us-return.dta&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;pd&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Избавимся от наблюдений с пропущенными значениями.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb51-1" data-line-number="1">df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;df&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb53-1" data-line-number="1">df.reset_index(drop<span class="op">=</span><span class="va">True</span>, inplace<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;df&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Переименуем столбцы.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb55-1" data-line-number="1">df <span class="op">=</span> df.rename(columns<span class="op">=</span>{<span class="st">&#39;A&#39;</span>:<span class="st">&#39;n&#39;</span>, <span class="st">&#39;B&#39;</span>: <span class="st">&#39;date&#39;</span>})</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;df&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb57-1" data-line-number="1">df[<span class="st">&#39;y&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;MOTOR&#39;</span>] <span class="op">-</span> df[<span class="st">&#39;RKFREE&#39;</span>]</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;df&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb59-1" data-line-number="1">df[<span class="st">&#39;x&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;MARKET&#39;</span>] <span class="op">-</span> df[<span class="st">&#39;RKFREE&#39;</span>] </a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;df&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Строим модель и читаем саммари :)</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb61-1" data-line-number="1">regr <span class="op">=</span> smf.ols(<span class="st">&#39;y~x&#39;</span>, data <span class="op">=</span> df).fit()</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;smf&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb63-1" data-line-number="1">regr.summary()</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Получить прогноз.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb65-1" data-line-number="1">df[<span class="st">&#39;yhat&#39;</span>] <span class="op">=</span> regr.fittedvalues</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Красивые графики для остатков, выборосов и прочих радостей, как в R, придется строить ручками. Зато приятно поиграть с оформлением :)</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb67-1" data-line-number="1">fig, ax <span class="op">=</span> plt.subplots()</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb69-1" data-line-number="1">ax.plot(df[<span class="st">&#39;x&#39;</span>],regr.fittedvalues, color<span class="op">=</span><span class="st">&#39;g&#39;</span>, alpha <span class="op">=</span><span class="fl">0.8</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;ax&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb71-1" data-line-number="1">ax.scatter(df[<span class="st">&#39;x&#39;</span>],regr.fittedvalues<span class="op">+</span>regr.resid, color <span class="op">=</span> <span class="st">&#39;g&#39;</span>, alpha <span class="op">=</span> <span class="fl">0.8</span>, s <span class="op">=</span> <span class="dv">40</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;ax&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb73-1" data-line-number="1">ax.vlines(df[<span class="st">&#39;x&#39;</span>],regr.fittedvalues,regr.fittedvalues<span class="op">+</span>regr.resid, color <span class="op">=</span> <span class="st">&#39;gray&#39;</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;ax&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb75-1" data-line-number="1">plt.title(<span class="st">&#39;Линия регрессии и остатки&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb77-1" data-line-number="1">plt.xlabel(<span class="st">&#39;RKFREE&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb79-1" data-line-number="1">plt.ylabel(<span class="st">&#39;MARKET&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb81-1" data-line-number="1">plt.show()</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Строим доверительный интервал.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb83-1" data-line-number="1">regr.conf_int()</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>И проведем F-test.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb85-1" data-line-number="1">hypotheses <span class="op">=</span> <span class="st">&#39;(x = 1)&#39;</span></a>
<a class="sourceLine" id="cb85-2" data-line-number="2">regr.f_test(r_matrix <span class="op">=</span> hypotheses)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Тест Шапиро. Такой же, как и в R. Для удобства можно поместить в табличку.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb87-1" data-line-number="1">W, p_value <span class="op">=</span> shapiro(regr.resid)</a>
<a class="sourceLine" id="cb87-2" data-line-number="2"><span class="co">#pd.DataFrame(data = {&#39;W&#39;: [round(W,3)], &#39;p_value&#39;: [round(p_value,3)]})</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;shapiro&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>Генерируем новые данные и строим предсказание.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb89-1" data-line-number="1"><span class="im">import</span> random</a>
<a class="sourceLine" id="cb89-2" data-line-number="2">random.seed(<span class="dv">7</span>)</a>
<a class="sourceLine" id="cb89-3" data-line-number="3"></a>
<a class="sourceLine" id="cb89-4" data-line-number="4">newData <span class="op">=</span> df[<span class="st">&#39;x&#39;</span>] <span class="op">+</span> <span class="fl">0.5</span><span class="op">*</span>np.random.normal(<span class="bu">len</span>(df))</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;df&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb91-1" data-line-number="1">prediction <span class="op">=</span> regr.predict(newData)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<p>А теперь жесть! Построим графички, похожие на autoplot R.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb93-1" data-line-number="1">fig_1 <span class="op">=</span> plt.figure(<span class="dv">1</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb95-1" data-line-number="1">fig_1.axes[<span class="dv">0</span>] <span class="op">=</span> sns.residplot(df[<span class="st">&#39;x&#39;</span>], df[<span class="st">&#39;y&#39;</span>],</a>
<a class="sourceLine" id="cb95-2" data-line-number="2">                                  lowess<span class="op">=</span><span class="va">True</span>,</a>
<a class="sourceLine" id="cb95-3" data-line-number="3">                                  scatter_kws<span class="op">=</span>{<span class="st">&#39;alpha&#39;</span>: <span class="fl">0.6</span>},</a>
<a class="sourceLine" id="cb95-4" data-line-number="4">                                  line_kws<span class="op">=</span>{<span class="st">&#39;color&#39;</span>: <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lw&#39;</span>: <span class="dv">2</span>, <span class="st">&#39;alpha&#39;</span>: <span class="fl">0.8</span>})</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;sns&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb97-1" data-line-number="1">fig_1.axes[<span class="dv">0</span>].set_title(<span class="st">&#39;Residuals vs Fitted&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_1&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb99-1" data-line-number="1">fig_1.axes[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;Fitted values&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_1&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb101-1" data-line-number="1">fig_1.axes[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;Residuals&#39;</span>)</a>
<a class="sourceLine" id="cb101-2" data-line-number="2"></a>
<a class="sourceLine" id="cb101-3" data-line-number="3"></a>
<a class="sourceLine" id="cb101-4" data-line-number="4"><span class="co"># можем добавить метки потенциальных аутлаеров</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_1&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb103-1" data-line-number="1">abs_resid <span class="op">=</span> <span class="bu">abs</span>(regr.resid).sort_values(ascending<span class="op">=</span><span class="va">False</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb105-1" data-line-number="1">abs_resid_top3 <span class="op">=</span> abs_resid[:<span class="dv">3</span>]</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;abs_resid&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb107-1" data-line-number="1"><span class="cf">for</span> i <span class="kw">in</span> abs_resid_top3.index:</a>
<a class="sourceLine" id="cb107-2" data-line-number="2">    fig_1.axes[<span class="dv">0</span>].annotate(i, </a>
<a class="sourceLine" id="cb107-3" data-line-number="3">                               xy<span class="op">=</span>(regr.fittedvalues[i], </a>
<a class="sourceLine" id="cb107-4" data-line-number="4">                                   regr.resid[i]))</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;abs_resid_top3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb109-1" data-line-number="1">norm_residuals <span class="op">=</span> regr.get_influence().resid_studentized_internal <span class="co"># сохраним стьюдентизированные остатки </span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb111-1" data-line-number="1">QQ <span class="op">=</span> gf.ProbPlot(norm_residuals)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;gf&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb113-1" data-line-number="1">fig_2 <span class="op">=</span> QQ.qqplot(line<span class="op">=</span><span class="st">&#39;45&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">&#39;b&#39;</span>, lw<span class="op">=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;QQ&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb115-1" data-line-number="1">fig_2.axes[<span class="dv">0</span>].set_title(<span class="st">&#39;Normal Q-Q&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb117-1" data-line-number="1">fig_2.axes[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;Theoretical Quantiles&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb119-1" data-line-number="1">fig_2.axes[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;Standardized Residuals&#39;</span>)<span class="op">;</span></a>
<a class="sourceLine" id="cb119-2" data-line-number="2"></a>
<a class="sourceLine" id="cb119-3" data-line-number="3"><span class="co">#и снова метки</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb121-1" data-line-number="1">abs_norm_resid <span class="op">=</span> np.flip(np.argsort(<span class="bu">abs</span>(norm_residuals)), <span class="dv">0</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;norm_residuals&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb123-1" data-line-number="1">abs_norm_resid_top3 <span class="op">=</span> abs_norm_resid[:<span class="dv">3</span>]</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;abs_norm_resid&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb125-1" data-line-number="1"><span class="cf">for</span> r, i <span class="kw">in</span> <span class="bu">enumerate</span>(abs_norm_resid_top3):</a>
<a class="sourceLine" id="cb125-2" data-line-number="2">    fig_2.axes[<span class="dv">0</span>].annotate(i, </a>
<a class="sourceLine" id="cb125-3" data-line-number="3">                               xy<span class="op">=</span>(np.flip(QQ.theoretical_quantiles, <span class="dv">0</span>)[r],</a>
<a class="sourceLine" id="cb125-4" data-line-number="4">                                   norm_residuals[i]))</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;abs_norm_resid_top3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb127-1" data-line-number="1">fig_3 <span class="op">=</span> plt.figure(<span class="dv">3</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb129-1" data-line-number="1">plt.scatter(regr.fittedvalues, np.sqrt(<span class="bu">abs</span>(norm_residuals)), alpha<span class="op">=</span><span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb131-1" data-line-number="1">sns.regplot(regr.fittedvalues, np.sqrt(<span class="bu">abs</span>(norm_residuals)), </a>
<a class="sourceLine" id="cb131-2" data-line-number="2">            scatter<span class="op">=</span><span class="va">False</span>, </a>
<a class="sourceLine" id="cb131-3" data-line-number="3">            ci<span class="op">=</span><span class="va">False</span>, </a>
<a class="sourceLine" id="cb131-4" data-line-number="4">            lowess<span class="op">=</span><span class="va">True</span>,</a>
<a class="sourceLine" id="cb131-5" data-line-number="5">            line_kws<span class="op">=</span>{<span class="st">&#39;color&#39;</span>: <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lw&#39;</span>: <span class="dv">1</span>, <span class="st">&#39;alpha&#39;</span>: <span class="fl">0.6</span>})</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;sns&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb133-1" data-line-number="1">fig_3.axes[<span class="dv">0</span>].set_title(<span class="st">&#39;Scale-Location&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb135-1" data-line-number="1">fig_3.axes[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;Fitted values&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb137-1" data-line-number="1">fig_3.axes[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;$\sqrt{|Standardized Residuals|}$&#39;</span>)</a>
<a class="sourceLine" id="cb137-2" data-line-number="2"></a>
<a class="sourceLine" id="cb137-3" data-line-number="3"><span class="co"># и еще раз!)</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb139-1" data-line-number="1">abs_sq_norm_resid <span class="op">=</span> np.flip(np.argsort(np.sqrt(<span class="bu">abs</span>(norm_residuals)), <span class="dv">0</span>))</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;norm_residuals&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb141-1" data-line-number="1">abs_sq_norm_resid_top3 <span class="op">=</span> abs_sq_norm_resid[:<span class="dv">3</span>]</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;abs_sq_norm_resid&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb143-1" data-line-number="1"><span class="cf">for</span> i <span class="kw">in</span> abs_sq_norm_resid_top3:</a>
<a class="sourceLine" id="cb143-2" data-line-number="2">    fig_3.axes[<span class="dv">0</span>].annotate(i, xy<span class="op">=</span>(regr.fittedvalues[i], </a>
<a class="sourceLine" id="cb143-3" data-line-number="3">                                   np.sqrt(<span class="bu">abs</span>(norm_residuals)[i])))</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;abs_sq_norm_resid_top3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb145-1" data-line-number="1">leverage <span class="op">=</span> regr.get_influence().hat_matrix_diag <span class="co"># сохраняем элементы матрицы-шляпницы</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb147-1" data-line-number="1">cook_dist <span class="op">=</span> regr.get_influence().cooks_distance[<span class="dv">0</span>] <span class="co"># и расстояние Кука</span></a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;regr&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb149-1" data-line-number="1">fig_4 <span class="op">=</span> plt.figure(<span class="dv">4</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb151-1" data-line-number="1">plt.scatter(leverage, norm_residuals, alpha<span class="op">=</span><span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb153-1" data-line-number="1">sns.regplot(leverage, norm_residuals, </a>
<a class="sourceLine" id="cb153-2" data-line-number="2">            scatter<span class="op">=</span><span class="va">False</span>, </a>
<a class="sourceLine" id="cb153-3" data-line-number="3">            ci<span class="op">=</span><span class="va">False</span>, </a>
<a class="sourceLine" id="cb153-4" data-line-number="4">            lowess<span class="op">=</span><span class="va">True</span>,</a>
<a class="sourceLine" id="cb153-5" data-line-number="5">            line_kws<span class="op">=</span>{<span class="st">&#39;color&#39;</span>: <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lw&#39;</span>: <span class="dv">1</span>, <span class="st">&#39;alpha&#39;</span>: <span class="fl">0.8</span>})</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;sns&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb155-1" data-line-number="1">fig_4.axes[<span class="dv">0</span>].set_xlim(<span class="dv">0</span>, <span class="fl">0.20</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_4&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb157-1" data-line-number="1">fig_4.axes[<span class="dv">0</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_4&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb159-1" data-line-number="1">fig_4.axes[<span class="dv">0</span>].set_title(<span class="st">&#39;Residuals vs Leverage&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_4&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb161-1" data-line-number="1">fig_4.axes[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;Leverage&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_4&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb163"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb163-1" data-line-number="1">fig_4.axes[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;Standardized Residuals&#39;</span>)</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;fig_4&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb165-1" data-line-number="1">leverage_top3 <span class="op">=</span> np.flip(np.argsort(cook_dist), <span class="dv">0</span>)[:<span class="dv">3</span>]</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;cook_dist&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb167-1" data-line-number="1"><span class="cf">for</span> i <span class="kw">in</span> leverage_top3:</a>
<a class="sourceLine" id="cb167-2" data-line-number="2">    fig_4.axes[<span class="dv">0</span>].annotate(i, </a>
<a class="sourceLine" id="cb167-3" data-line-number="3">                               xy<span class="op">=</span>(leverage[i], </a>
<a class="sourceLine" id="cb167-4" data-line-number="4">                                   norm_residuals[i]))</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;leverage_top3&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb169-1" data-line-number="1">plt.show()</a></code></pre></div>
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
</div>
<div id="stata" class="section level2">
<h2><span class="header-section-number">3.3</span> stata</h2>
<p>Загружаем данные.</p>
<pre class="stata"><code>use data/us-return.dta</code></pre>
<pre><code>
Любуемся и даем новые названия столбцам.


```stata
summarize
ren A n
ren B date
```

```
    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
           A |        120        60.5    34.78505          1        120
           B |          0
       MOBIL |        120    .0161917    .0803075      -.178       .366
      TEXACO |        120    .0119417    .0797036      -.194       .399
         IBM |        120    .0096167     .059024      -.187        .15
-------------+---------------------------------------------------------
         DEC |        120      .01975    .0991438      -.364       .385
      DATGEN |        120    .0074833    .1275399      -.342       .528
       CONED |        120    .0185083    .0502719      -.139       .151
        PSNH |        120   -.0042167    .1094712      -.485       .318
       WEYER |        120    .0096333    .0850664      -.271        .27
-------------+---------------------------------------------------------
       BOISE |        120     .016675    .0974882      -.274       .379
       MOTOR |        120    .0181583    .0972656      -.331        .27
       TANDY |        120    .0250083     .127566      -.246       .454
       PANAM |        120    .0035167    .1318054      -.313       .406
       DELTA |        120    .0116917    .0959317       -.26       .289
-------------+---------------------------------------------------------
      CONTIL |        120      -.0011    .1506992        -.6       .974
      CITCRP |        120    .0118583    .0809719      -.282       .318
      GERBER |        120       .0164    .0877379      -.288       .234
      GENMIL |        120    .0165833    .0650403      -.148        .19
      MARKET |        120    .0139917    .0683532       -.26       .148
-------------+---------------------------------------------------------
      RKFREE |        120    .0068386    .0021869     .00207     .01255
      rkfree |        120    .0068386    .0021869     .00207     .01255

```

Убираем пропущенные значения и создаем новые переменные.

```stata
drop if n == .
gen y = MOTOR - RKFREE
gen x = MARKET - RKFREE
```

```
(2,544 observations deleted)

```

Строим модель и проверяем гипотезу об адекватности регрессии. Тут же получаем доверительные интервалы для коэффициентов.

```stata
reg y x
```

```
      Source |       SS           df       MS      Number of obs   =       120
-------------+----------------------------------   F(1, 118)       =     65.48
       Model |  .402913404         1  .402913404   Prob &gt; F        =    0.0000
    Residual |  .726081541       118  .006153233   R-squared       =    0.3569
-------------+----------------------------------   Adj R-squared   =    0.3514
       Total |  1.12899494       119  .009487352   Root MSE        =    .07844

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .8481496   .1048138     8.09   0.000     .6405898    1.055709
       _cons |   .0052529   .0071999     0.73   0.467     -.009005    .0195107
------------------------------------------------------------------------------
```

Проверим гипотезу о равенстве коэффициента при регрессоре единице. 

```stata
test x = 1
```

```
 ( 1)  x = 1

       F(  1,   118) =    2.10
            Prob &gt; F =    0.1501
```

Сделаем предсказание по выборке и сохраним остатки.

```stata
predict u_hat, resid
predict y_hat
```

```
(option xb assumed; fitted values)
```

Протестируем остатки регрессии на нормальность с помощью теста Харке-Бера.
На самом деле, это не совсем тест Харке-Бера. Оригинальный вариант ассимптотический и в нем нет поправки на размер выборки. В Stata есть. Подробнее здесь https://www.stata.com/manuals13/rsktest.pdf


```stata
sktest u_hat
```

```
                    Skewness/Kurtosis tests for Normality
                                                          ------ joint ------
    Variable |        Obs  Pr(Skewness)  Pr(Kurtosis) adj chi2(2)   Prob&gt;chi2
-------------+---------------------------------------------------------------
       u_hat |        120     0.8841        0.1027        2.74         0.2539
```

И тест Шапиро-Уилка. Тут все аналогично R.

```stata
swilk u_hat
```

```
                   Shapiro-Wilk W test for normal data

    Variable |        Obs       W           V         z       Prob&gt;z
-------------+------------------------------------------------------
       u_hat |        120    0.99021      0.942    -0.133    0.55310
```

Гипотеза о нормальности остатков не отвергается.

QQ - график


```stata
qnorm u_hat 
```
![](qq_plot.png)

График предсказанных значений против остатков.

```stata
rvfplot, yline(0)
```
![](resvsfit.png)

График диагональных элементов матрицы-шляпницы против квадрата остатков (по сравнению с R оси поменялись местами).

```stata
lvr2plot
```
![](resvsh.png)

График предсказанных значений против стандартизиованных остатков. Размер точек на графике зависит от расстояния Кука для данного наблюдения.

```stata
predict D, cooksd
predict standard, rstandard

graph twoway scatter standard y_hat [aweight=D], msymbol(oh) yline(0)
```
![](standardhat.png)


```stata
set seed 7

set obs 120
gen x_new = x+ 0.5 * rnormal()
gen y_hat_new =  .8481496 * x_new + .0052529 
```

```
 translator Graph2png not found
r(111);



number of observations (_N) was 120, now 120

```


&lt;!--chapter:end:02-simplereg.Rmd--&gt;

# Модель бинарного выбора {#binchoice}




&gt; Сейчас попробуем подружиться с моделями бинарного выбора на основе данных `bwght.dta`, где зависимая переменная отражает, является индивид курильщиком или нет.

## r

Загрузим необходимы пакеты.

```r
library(rio) # импорт и экспорт данных в разных форматах
library(tidyverse) # графики и манипуляции с данными
library(skimr) # описательные статистики
library(mfx) # нахождение предельных эффектов
library(margins) # визуализация предельных эффектов
library(lmtest) # проведение тестов
library(plotROC) # построение ROC-кривой
library(caret) # confusion-матрица
library(texreg) # вывод результатов регрессии в тех и html
```
Импортируем исследуемые данные.

```r
data = import(&quot;data/bwght.dta&quot;) 
```
Сгенерируем переменную `smoke`, отражающее состояние отдельного индивида: курильщик, если `smoke = 1`, не курильщик - иначе. 

```r
data = mutate(data, smoke=(cigs&gt;0))
```
Рассмотрим описательные статистики по всем переменным: решение курить, семейный доход, налог на сигареты, цена сигарет, образование отца и матери, паритет, цвет кожи.

```r
skim(data)
```

```
Skim summary statistics
 n obs: 1388 
 n variables: 15 

── Variable type:logical ───────────────────────────────────────────────────────────────────
 variable missing complete    n mean                      count
    smoke       0     1388 1388 0.15 FAL: 1176, TRU: 212, NA: 0

── Variable type:numeric ───────────────────────────────────────────────────────────────────
 variable missing complete    n   mean    sd     p0    p25    p50    p75
    bwght       0     1388 1388 118.7  20.35  23    107    120    132   
 bwghtlbs       0     1388 1388   7.42  1.27   1.44   6.69   7.5    8.25
 cigprice       0     1388 1388 130.56 10.24 103.8  122.8  130.8  137   
     cigs       0     1388 1388   2.09  5.97   0      0      0      0   
   cigtax       0     1388 1388  19.55  7.8    2     15     20     26   
   faminc       0     1388 1388  29.03 18.74   0.5   14.5   27.5   37.5 
 fatheduc     196     1192 1388  13.19  2.75   1     12     12     16   
   lbwght       0     1388 1388   4.76  0.19   3.14   4.67   4.79   4.88
  lfaminc       0     1388 1388   3.07  0.92  -0.69   2.67   3.31   3.62
     male       0     1388 1388   0.52  0.5    0      0      1      1   
 motheduc       1     1387 1388  12.94  2.38   2     12     12     14   
    packs       0     1388 1388   0.1   0.3    0      0      0      0   
   parity       0     1388 1388   1.63  0.89   1      1      1      2   
    white       0     1388 1388   0.78  0.41   0      1      1      1   
   p100     hist
 271    ▁▁▆▇▁▁▁▁
  16.94 ▁▁▆▇▁▁▁▁
 152.5  ▂▁▃▇▅▇▁▂
  50    ▇▁▁▁▁▁▁▁
  38    ▂▅▃▇▅▇▂▂
  65    ▆▆▇▇▃▅▁▆
  18    ▁▁▁▁▂▇▂▅
   5.6  ▁▁▁▁▃▇▁▁
   4.17 ▁▁▁▁▂▅▇▇
   1    ▇▁▁▁▁▁▁▇
  18    ▁▁▁▂▇▃▃▁
   2.5  ▇▁▁▁▁▁▁▁
   6    ▇▃▁▂▁▁▁▁
   1    ▂▁▁▁▁▁▁▇
```
Заметим существование пропущенных переменных у `fatheduc`, `motheduc`. Будем анализировать только те значения, у которых нет пропущенных наблюдений. Для этого создадим новый dataframe, `data_2`, в котором отсутствуют пропущенные значения. Просмотрим его описательные статистики.

```r
data_2 = filter(data, !is.na(fatheduc), !is.na(motheduc))
skim(data_2)
```

```
Skim summary statistics
 n obs: 1191 
 n variables: 15 

── Variable type:logical ───────────────────────────────────────────────────────────────────
 variable missing complete    n mean                      count
    smoke       0     1191 1191 0.14 FAL: 1030, TRU: 161, NA: 0

── Variable type:numeric ───────────────────────────────────────────────────────────────────
 variable missing complete    n    mean    sd     p0    p25    p50    p75
    bwght       0     1191 1191 119.53  20.14  23    108    120    132   
 bwghtlbs       0     1191 1191   7.47   1.26   1.44   6.75   7.5    8.25
 cigprice       0     1191 1191 130.71  10.35 103.8  122.8  130.8  137   
     cigs       0     1191 1191   1.77   5.34   0      0      0      0   
   cigtax       0     1191 1191  19.6    7.86   2     15     20     26   
   faminc       0     1191 1191  32.22  17.96   0.5   18.5   27.5   42.5 
 fatheduc       0     1191 1191  13.19   2.74   1     12     12     16   
   lbwght       0     1191 1191   4.77   0.19   3.14   4.68   4.79   4.88
  lfaminc       0     1191 1191   3.28   0.72  -0.69   2.92   3.31   3.75
     male       0     1191 1191   0.52   0.5    0      0      1      1   
 motheduc       0     1191 1191  13.13   2.42   2     12     12     15   
    packs       0     1191 1191   0.088  0.27   0      0      0      0   
   parity       0     1191 1191   1.61   0.87   1      1      1      2   
    white       0     1191 1191   0.84   0.36   0      1      1      1   
   p100     hist
 271    ▁▁▆▇▁▁▁▁
  16.94 ▁▁▆▇▁▁▁▁
 152.5  ▂▁▃▇▅▇▁▂
  40    ▇▁▁▁▁▁▁▁
  38    ▂▅▃▇▆▇▂▂
  65    ▂▅▇▇▃▅▁▆
  18    ▁▁▁▁▂▇▂▅
   5.6  ▁▁▁▁▂▇▁▁
   4.17 ▁▁▁▁▁▃▇▇
   1    ▇▁▁▁▁▁▁▇
  18    ▁▁▁▂▇▃▃▂
   2    ▇▁▁▁▁▁▁▁
   6    ▇▃▁▂▁▁▁▁
   1    ▂▁▁▁▁▁▁▇
```
Построим модель линейной вероятности. Сохраним результат под `lin_prob_model`. 

```r
lin_prob_model = lm(smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white, data=data_2)
summary(lin_prob_model)
```

```

Call:
lm(formula = smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + 
    motheduc + parity + white, data = data_2)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.46295 -0.17696 -0.11495 -0.02127  1.01628 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.4297071  0.2270444   1.893   0.0587 .  
faminc      -0.0014813  0.0006325  -2.342   0.0193 *  
cigtax       0.0008334  0.0026320   0.317   0.7516    
cigprice     0.0007472  0.0019954   0.374   0.7081    
fatheduc    -0.0064880  0.0047493  -1.366   0.1722    
motheduc    -0.0242416  0.0053373  -4.542 6.14e-06 ***
parity       0.0019565  0.0110725   0.177   0.8598    
white        0.0471603  0.0273790   1.723   0.0852 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.3318 on 1183 degrees of freedom
Multiple R-squared:  0.06448,   Adjusted R-squared:  0.05895 
F-statistic: 11.65 on 7 and 1183 DF,  p-value: 2.184e-14
```
Посмотрим на число совпадений прогноза и исходных значений. Для этого оценим предсказанные значения модели линейной вероятности. Сохраним значение как `predictions_lin_prob_model`.

```r
predictions_lin_prob_model = predict(lin_prob_model)
```
Генерируем `smoke_ols` как 1, если вероятность по модели больше 0.5 и 0, если она меньше 0.5.

```r
smoke_ols = 1 * (predictions_lin_prob_model&gt;0.5)
```
Число совпадений данных и прогноза модели линейной вероятности:

```r
sum (smoke_ols == data_2$smoke)
```

```
[1] 1030
```
Известно, что модель линейной вероятности обладает значительными недостатками, в частности: нереалистичное значение оцененной вероятности, ошибки, распределённые не нормально и гетероскедастичность. Поэтому оценим `P(smoke=1|x)`, и построим логит- и пробит-модели. 
Немного о логит-модели: предполагается, что существует скрытая (латентная) переменная, для которой строится модель, $$ y^*_i = \beta_1 + \beta_2 \cdot X_i + \varepsilon_i$$,так, что:

\[
\begin{equation*}
Y_i = 
 \begin{cases}
   1, &amp;\text{если ${y_i}^* \geqslant 0$}\\
   0, &amp;\text{если ${y_i}^* &lt; 0$}
 \end{cases}
\end{equation*}
\]

 $$\varepsilon_i \sim logistic, \\f(t) = \frac{e^{-t}}{(1 + e^{-t})^2}$$
 
Построим логит-модель и сохраним результат оцененной модели как `logit_model`.

```r
logit_model = glm(smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white, x=TRUE, data=data_2, family=binomial(link=&quot;logit&quot;))
summary(logit_model)
```

```

Call:
glm(formula = smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + 
    motheduc + parity + white, family = binomial(link = &quot;logit&quot;), 
    data = data_2, x = TRUE)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.5699  -0.5878  -0.4379  -0.2854   2.6434  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  0.960628   2.083625   0.461  0.64477    
faminc      -0.017142   0.006401  -2.678  0.00741 ** 
cigtax       0.013859   0.024435   0.567  0.57058    
cigprice     0.004156   0.018280   0.227  0.82014    
fatheduc    -0.054616   0.041813  -1.306  0.19148    
motheduc    -0.224467   0.049228  -4.560 5.12e-06 ***
parity      -0.008435   0.097275  -0.087  0.93090    
white        0.436632   0.260283   1.678  0.09344 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 943.55  on 1190  degrees of freedom
Residual deviance: 862.11  on 1183  degrees of freedom
AIC: 878.11

Number of Fisher Scoring iterations: 5
```
Так как коэффициенты логит- и пробит- моделей плохо интерпретируются, поскольку единицы измерения латентной переменной определить сложно, посчитаем предельные эффекты, то есть изменение вероятности решения курить с изменением фактора на 1 единицу. 

Для предельного эффекта в средних значениях факторов:

```r
logitmfx(smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white, data=data_2, atmean=TRUE)
```

```
Call:
logitmfx(formula = smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + 
    motheduc + parity + white, data = data_2, atmean = TRUE)

Marginal Effects:
               dF/dx   Std. Err.       z     P&gt;|z|    
faminc   -0.00168111  0.00061396 -2.7382  0.006178 ** 
cigtax    0.00135920  0.00239324  0.5679  0.570081    
cigprice  0.00040759  0.00179294  0.2273  0.820165    
fatheduc -0.00535620  0.00409569 -1.3078  0.190953    
motheduc -0.02201350  0.00469099 -4.6927 2.696e-06 ***
parity   -0.00082727  0.00953824 -0.0867  0.930885    
white     0.03815415  0.02011210  1.8971  0.057818 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

dF/dx is for discrete change for the following variables:

[1] &quot;white&quot;
```

```r
margins = margins(logit_model)
plot(margins)
```

&lt;img src=&quot;03-binchoice_files/figure-html/unnamed-chunk-11-1.png&quot; width=&quot;672&quot; style=&quot;display: block; margin: auto;&quot; /&gt;
Интерпретация предельных эффектов следующая (на примере переменной семейного дохода): при увеличении семейного дохода в среднем на 1 единицу при остальных неизменных факторах, вероятность стать курильщиком уменьшается в среднем на 0.18%. 

Визуализируем предельный эффект для семейного дохода:

```r
cplot(logit_model, &quot;faminc&quot;, what=&quot;effect&quot;, main=&quot;Average Marginal Effect of Faminc&quot;)
```

&lt;img src=&quot;03-binchoice_files/figure-html/unnamed-chunk-12-1.png&quot; width=&quot;672&quot; style=&quot;display: block; margin: auto;&quot; /&gt;
Для определения качества модели построим классификационную матрицу. Для этого сначала вычислим предсказания логит-модели, `predictions_logit_model`. Так как результат не бинарный, то введём порог отсечения, равный 0.5. Назовём бинарный результат `smoke_logit`:

```r
predictions_logit_model = predict(logit_model)
smoke_logit_model = (predictions_logit_model&gt;0.5)
```
Построим классификационную матрицу. При возникновении ошибок аргументов, в частности, при несовпадении их размера или типа, можно воспользоваться функцией `as.factor()`.

```r
confusionMatrix(as.factor(smoke_logit_model), as.factor(data_2$smoke))
```

```
Confusion Matrix and Statistics

          Reference
Prediction FALSE TRUE
     FALSE  1029  161
     TRUE      1    0
                                         
               Accuracy : 0.864          
                 95% CI : (0.8432, 0.883)
    No Information Rate : 0.8648         
    P-Value [Acc &gt; NIR] : 0.5546         
                                         
                  Kappa : -0.0017        
                                         
 Mcnemar&#39;s Test P-Value : &lt;2e-16         
                                         
            Sensitivity : 0.9990         
            Specificity : 0.0000         
         Pos Pred Value : 0.8647         
         Neg Pred Value : 0.0000         
             Prevalence : 0.8648         
         Detection Rate : 0.8640         
   Detection Prevalence : 0.9992         
      Balanced Accuracy : 0.4995         
                                         
       &#39;Positive&#39; Class : FALSE          
                                         
```
Качество модели также можно проанализировать с помощью ROC-кривой, отражающей зависимость доли верных положительно классифицируемых наблюдений (`sensitivity`) от доли ложных положительно классифицируемых наблюдений `(1-specifity)`. 

Построим ROC-кривую для логит-модели:

```r
basicplot = ggplot(data_2, aes(m=predictions_logit_model, d=data_2$smoke)) + geom_roc()
basicplot + annotate(&quot;text&quot;, x = .75, y = .25, 
           label = paste(&quot;AUC =&quot;, round(calc_auc(basicplot)$AUC, 2)))
```

&lt;img src=&quot;03-binchoice_files/figure-html/unnamed-chunk-15-1.png&quot; width=&quot;672&quot; style=&quot;display: block; margin: auto;&quot; /&gt;
Площадь под кривой обозначается как AUC. Он показывает качество классификации. Соответственно, чем выше AUC, тем лучше построенная модель.

Теперь рассмотрим логит-модель, не учитывающую переменную `white`. Сохраним эту логит-модель под названием `logit_model_new`. 

```r
logit_model_new = glm(smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity, x=TRUE, data=data_2, family=binomial(link=&quot;logit&quot;))
```
Сравним модели `logit_model` и `logit_model_new` с помощью теста максимального правдоподобия (likelihood ratio test).

```r
lrtest(logit_model,logit_model_new)
```

```
Likelihood ratio test

Model 1: smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + 
    parity + white
Model 2: smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + 
    parity
  #Df  LogLik Df  Chisq Pr(&gt;Chisq)  
1   8 -431.06                       
2   7 -432.55 -1 2.9988    0.08333 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
```
`p-value = 0.08` в LR-тесте. Следовательно, основная гипотеза о том, что переменная `white` не влияет на решение стать курильщиком, не отвергается на 5% уровне значимости.

Сейчас посмотрим на пробит-модель. Скрытая переменная в этой модели распределена стандартно нормально: 
\[
f(t) = \frac{1 \cdot e^{\frac{-t^2}{2}}}{\sqrt{2 \cdot \pi}}
\]

Построим пробит-модель.

```r
probit_model = glm(smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white, data=data_2, family=binomial(link=&quot;probit&quot;))
summary(probit_model)
```

```

Call:
glm(formula = smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + 
    motheduc + parity + white, family = binomial(link = &quot;probit&quot;), 
    data = data_2)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.5255  -0.5947  -0.4376  -0.2607   2.7564  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  0.393063   1.130957   0.348  0.72818    
faminc      -0.008873   0.003376  -2.628  0.00858 ** 
cigtax       0.005892   0.013245   0.445  0.65643    
cigprice     0.003561   0.009930   0.359  0.71987    
fatheduc    -0.034593   0.023160  -1.494  0.13527    
motheduc    -0.125693   0.027090  -4.640 3.49e-06 ***
parity      -0.003052   0.053610  -0.057  0.95460    
white        0.242348   0.140052   1.730  0.08356 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 943.55  on 1190  degrees of freedom
Residual deviance: 858.93  on 1183  degrees of freedom
AIC: 874.93

Number of Fisher Scoring iterations: 5
```
Вычисление предельных эффектов и их интерпретация, построение классификационной матрицы и ROC-кривой и LR-тест проводятся аналогично выполненным в логит-модели.
Выведем сравнительную таблицу для построенных моделей.

```r
screenreg(list(lin_prob_model, logit_model, probit_model), 
             custom.model.names = c(&quot;Модель линейной   вероятности&quot;, &quot;Логит-модель&quot;, &quot;Пробит-модель&quot;))
```

```

==========================================================================
                Модель линейной   вероятности  Логит-модель  Пробит-модель
--------------------------------------------------------------------------
(Intercept)        0.43                           0.96          0.39      
                  (0.23)                         (2.08)        (1.13)     
faminc            -0.00 *                        -0.02 **      -0.01 **   
                  (0.00)                         (0.01)        (0.00)     
cigtax             0.00                           0.01          0.01      
                  (0.00)                         (0.02)        (0.01)     
cigprice           0.00                           0.00          0.00      
                  (0.00)                         (0.02)        (0.01)     
fatheduc          -0.01                          -0.05         -0.03      
                  (0.00)                         (0.04)        (0.02)     
motheduc          -0.02 ***                      -0.22 ***     -0.13 ***  
                  (0.01)                         (0.05)        (0.03)     
parity             0.00                          -0.01         -0.00      
                  (0.01)                         (0.10)        (0.05)     
white              0.05                           0.44          0.24      
                  (0.03)                         (0.26)        (0.14)     
--------------------------------------------------------------------------
R^2                0.06                                                   
Adj. R^2           0.06                                                   
Num. obs.       1191                           1191          1191         
RMSE               0.33                                                   
AIC                                             878.11        874.93      
BIC                                             918.77        915.59      
Log Likelihood                                 -431.06       -429.46      
Deviance                                        862.11        858.93      
==========================================================================
*** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05
```

## python

Попробуем повторить эти шаги, используя **python**.

Импортируем пакеты:

```python
import numpy as np
import pandas as pd # чтение файлов
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;pandas&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
import matplotlib.pyplot as plt # построение графиков
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;matplotlib&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
from statsmodels.formula.api import logit, probit, ols # построение логит-, пробит - и линейной регрессий
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;statsmodels&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
import statistics # описательные статистики
import sklearn
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;sklearn&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
from sklearn import metrics # для работы с классификационными матрицами
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;sklearn&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
from sklearn.metrics import roc_curve, auc  # ROC-curve и AUC
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;sklearn&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
from scipy.stats.distributions import chi2 # хи-квадрат-статистика
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): ModuleNotFoundError: No module named &#39;scipy&#39;

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Загрузим данные:

```python
data = pd.read_stata(&quot;data/bwght.dta&quot;)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;pd&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Уберём пропущенные данные.Выведем описательные статистики по данным.

```python
data_2 = data.dropna()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;data&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
data_2.describe()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;data_2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Создадим бинарную переменную `smoke`:

```python
data_2[&#39;smoke&#39;] = 1 * (data_2[&#39;cigs&#39;]&gt;0)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;data_2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Построим модель линейной вероятности:

```python
lin_prob_model = ols(&quot;smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white&quot;, data_2).fit()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;ols&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
lin_prob_model.summary()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;lin_prob_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Создадим переменную `predictions__lin_prob_model`, равную прогнозным значениям модели линейной вероятности, и посмотрим на число совпадений исходных и прогнозных данных.

```python
predictions_lin_prob_model = lin_prob_model.predict(data_2)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;lin_prob_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
data_2[&#39;smoke_ols&#39;] = 1 * (predictions_lin_prob_model&gt;0.5)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;predictions_lin_prob_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
sum(data_2[&#39;smoke&#39;]==data_2[&#39;smoke_ols&#39;])
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;data_2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Построим логит-модель.

```python
logit_model = logit(&quot;smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white&quot;, data_2).fit()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
logit_model.summary()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Посчитаем предельные эффекты в средних значениях переменных для логистической регрессии.

```python
me_mean = logit_model.get_margeff(at=&#39;mean&#39;)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
me_mean.summary()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;me_mean&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

Посмотрим на точность классификации построенной логит-модели. Для этого вычислим прогнозные значения модели.


```python
predictions_logit_pred = logit_model.predict(data_2) # прогнозирование значений
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
data_2[&#39;smoke_logit_model&#39;] = 1 * (predictions_logit_pred&gt;0.5)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;predictions_logit_pred&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Построим классификационную матрицу.

```python
sklearn.metrics.confusion_matrix(data_2[&#39;smoke&#39;], data_2[&#39;smoke_logit_model&#39;])
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;sklearn&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Точность прогноза и классификационные данные.

```python
np.round(sklearn.metrics.accuracy_score(data_2[&#39;smoke&#39;],data_2[&#39;smoke_logit_model&#39;]), 2)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;sklearn&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
sklearn.metrics.classification_report(data_2[&#39;smoke&#39;], data_2[&#39;smoke_logit_model&#39;])
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;sklearn&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Выведем ROC-кривую для логит-модели.

```python
fpr, tpr, thresholds = metrics.roc_curve(data_2[&#39;smoke&#39;], predictions_logit_pred)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;metrics&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
auc = metrics.roc_auc_score(data_2[&#39;smoke&#39;], predictions_logit_pred)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;metrics&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
plt.plot(fpr,tpr,label=&quot;auc=&quot;+str(np.round(auc, 2)))
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
plt.legend(loc=4)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
plt.xlabel(&#39;1-Specifity&#39;)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
plt.ylabel(&#39;Sensitivity&#39;)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
plt.title(&#39;ROC-curve&#39;)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
plt.show()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;plt&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Построим новую логит-модель (`logit_model_new`) без учёта переменной `white`.

```python
logit_model_new = logit(&quot;smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity &quot;, data_2).fit()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
logit_model_new.summary()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit_model_new&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Так как на момент написания коана готовой реализации функции теста отношения правдоподобия нет, то сделаем его ручками.

```python
L1 = logit_model.llf
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
L2 = logit_model_new.llf
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;logit_model_new&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
def likelihood_ratio(llmin, llmax):
    return(2*(max(llmax, llmin) - min(llmax, llmin)))
LR = likelihood_ratio (L1, L2)
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;L1&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
np.round(chi2.sf(LR, 1), 2) # расчёт p-value для теста
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;chi2&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Основная гипотеза о незначимости фактора `white` не отвергается на 5% уровне значимости. 
Построим пробит-модель.

```python
probit_model = probit(&quot;smoke ~ 1 + faminc + cigtax + cigprice + fatheduc + motheduc + parity + white&quot;, data_2).fit()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;probit&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

```python
probit_model.summary()
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;probit_model&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```
Расчёт предельных эффектов, точности классификации, визуализация ROC-кривой и проведение LR-теста проводятся аналогично операциям с логит-моделью.
Сравнение моделей.

```python
pd.DataFrame(dict(col1=lin_prob_model.params, col2=logit_model.params, col3=probit_model.params))
```

```
Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name &#39;pd&#39; is not defined

Detailed traceback: 
  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
```

## stata

А сейчас познакомимся с тем, как **stata** работает с моделями бинарного выбора.

Импортируем данные.



```stata
use data/bwght.dta
```
</code></pre>
<p>Сгенерируем переменную <code>smoke</code>.</p>
<pre class="stata"><code>gen smoke = (cigs&gt;0) if cigs != .</code></pre>
<pre><code>Рассмотрим описательные статистики dataframe.

```stata
sum smoke faminc cigtax cigprice fatheduc motheduc parity white
```

```
    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
       smoke |      1,388    .1527378    .3598642          0          1
      faminc |      1,388    29.02666    18.73928         .5         65
      cigtax |      1,388    19.55295    7.795598          2         38
    cigprice |      1,388     130.559    10.24448      103.8      152.5
    fatheduc |      1,192    13.18624    2.745985          1         18
-------------+---------------------------------------------------------
    motheduc |      1,387    12.93583    2.376728          2         18
      parity |      1,388    1.632565    .8940273          1          6
       white |      1,388    .7845821    .4112601          0          1
```
Уберём пропущенные наблюдения.

```stata
sum smoke faminc cigtax cigprice fatheduc motheduc parity white if fatheduc != . &amp; motheduc != .
```

```
&gt; = . &amp; motheduc != .

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
       smoke |      1,191    .1351805    .3420599          0          1
      faminc |      1,191    32.21914     17.9562         .5         65
      cigtax |      1,191    19.60327    7.859844          2         38
    cigprice |      1,191    130.7097    10.35128      103.8      152.5
    fatheduc |      1,191    13.19144    2.741274          1         18
-------------+---------------------------------------------------------
    motheduc |      1,191     13.1251    2.417437          2         18
      parity |      1,191     1.61377    .8746352          1          6
       white |      1,191    .8438287    .3631701          0          1
```
Построим модель линейной вероятности. Сохраним результат под `lin_prob_model`.

```stata
reg smoke faminc cigtax cigprice fatheduc motheduc parity white if fatheduc != . &amp; motheduc != .
est store lin_prob_model
```

```
&gt; = . &amp; motheduc != .

      Source |       SS           df       MS      Number of obs   =     1,191
-------------+----------------------------------   F(7, 1183)      =     11.65
       Model |  8.97813534         7  1.28259076   Prob &gt; F        =    0.0000
    Residual |  130.257801     1,183  .110108031   R-squared       =    0.0645
-------------+----------------------------------   Adj R-squared   =    0.0589
       Total |  139.235936     1,190  .117004988   Root MSE        =    .33183

------------------------------------------------------------------------------
       smoke |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      faminc |  -.0014813   .0006325    -2.34   0.019    -.0027223   -.0002404
      cigtax |   .0008334    .002632     0.32   0.752    -.0043306    .0059974
    cigprice |   .0007472   .0019954     0.37   0.708    -.0031676    .0046621
    fatheduc |   -.006488   .0047493    -1.37   0.172    -.0158059    .0028299
    motheduc |  -.0242416   .0053373    -4.54   0.000    -.0347132   -.0137699
      parity |   .0019565   .0110725     0.18   0.860    -.0197675    .0236805
       white |   .0471603    .027379     1.72   0.085    -.0065564    .1008771
       _cons |   .4297071   .2270444     1.89   0.059    -.0157474    .8751616
------------------------------------------------------------------------------
```
Посчитаем количество совпадений прогнозов и исходных значений.

```stata
predict predictions_lin_prob_model
gen smoke_ols = (predictions_lin_prob_model&gt;0.5) if predictions_lin_prob_model != .
count if smoke_ols == smoke
tab smoke_ols smoke
```

```
(option xb assumed; fitted values)
(197 missing values generated)

(197 missing values generated)

  1,030

           |         smoke
 smoke_ols |         0          1 |     Total
-----------+----------------------+----------
         0 |     1,030        161 |     1,191 
-----------+----------------------+----------
     Total |     1,030        161 |     1,191 
```
Построим логит-модель и сохраним результат оцененной модели как `logit_model`.

```stata
logit smoke faminc cigtax cigprice fatheduc motheduc parity white if fatheduc != . &amp; motheduc != .
est store logit_model
```

```
&gt;  != . &amp; motheduc != .

Iteration 0:   log likelihood = -471.77574  
Iteration 1:   log likelihood = -434.01279  
Iteration 2:   log likelihood =  -431.0609  
Iteration 3:   log likelihood = -431.05512  
Iteration 4:   log likelihood = -431.05512  

Logistic regression                             Number of obs     =      1,191
                                                LR chi2(7)        =      81.44
                                                Prob &gt; chi2       =     0.0000
Log likelihood = -431.05512                     Pseudo R2         =     0.0863

------------------------------------------------------------------------------
       smoke |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      faminc |  -.0171419   .0064012    -2.68   0.007     -.029688   -.0045959
      cigtax |   .0138594   .0244353     0.57   0.571    -.0340328    .0617517
    cigprice |   .0041561   .0182797     0.23   0.820    -.0316715    .0399838
    fatheduc |  -.0546159   .0418127    -1.31   0.191    -.1365673    .0273354
    motheduc |  -.2244665   .0492286    -4.56   0.000    -.3209528   -.1279803
      parity |  -.0084354   .0972749    -0.09   0.931    -.1990908    .1822199
       white |   .4366317   .2602835     1.68   0.093    -.0735145    .9467779
       _cons |   .9606284   2.083634     0.46   0.645    -3.123219    5.044476
------------------------------------------------------------------------------
```
Рассчитаем предельные эффекты в средних значениях переменных.

```stata
margins, dydx(*) atmeans
```

```
Conditional marginal effects                    Number of obs     =      1,191
Model VCE    : OIM

Expression   : Pr(smoke), predict()
dy/dx w.r.t. : faminc cigtax cigprice fatheduc motheduc parity white
at           : faminc          =    32.21914 (mean)
               cigtax          =    19.60327 (mean)
               cigprice        =    130.7097 (mean)
               fatheduc        =    13.19144 (mean)
               motheduc        =     13.1251 (mean)
               parity          =     1.61377 (mean)
               white           =    .8438287 (mean)

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      faminc |  -.0016811    .000614    -2.74   0.006    -.0028845   -.0004778
      cigtax |   .0013592   .0023933     0.57   0.570    -.0033315    .0060499
    cigprice |   .0004076   .0017929     0.23   0.820    -.0031065    .0039217
    fatheduc |  -.0053562   .0040957    -1.31   0.191    -.0133836    .0026712
    motheduc |  -.0220135    .004691    -4.69   0.000    -.0312077   -.0128193
      parity |  -.0008273   .0095383    -0.09   0.931    -.0195219    .0178674
       white |   .0428206   .0254261     1.68   0.092    -.0070136    .0926548
------------------------------------------------------------------------------
```
Визуализируем предельные эффекты.

```stata
marginsplot
```
![](marginsplot1.png)

Посмотрим на точность классификации построенной логит-модели. Для этого применяется простая команда:

```stata
estat classification
```

```
 translator Graph2png not found
r(111);



Logistic model for smoke

              -------- True --------
Classified |         D            ~D  |      Total
-----------+--------------------------+-----------
     +     |         0             3  |          3
     -     |       161          1027  |       1188
-----------+--------------------------+-----------
   Total   |       161          1030  |       1191

Classified + if predicted Pr(D) &gt;= .5
True D defined as smoke != 0
--------------------------------------------------
Sensitivity                     Pr( +| D)    0.00%
Specificity                     Pr( -|~D)   99.71%
Positive predictive value       Pr( D| +)    0.00%
Negative predictive value       Pr(~D| -)   86.45%
--------------------------------------------------
False + rate for true ~D        Pr( +|~D)    0.29%
False - rate for true D         Pr( -| D)  100.00%
False + rate for classified +   Pr(~D| +)  100.00%
False - rate for classified -   Pr( D| -)   13.55%
--------------------------------------------------
Correctly classified                        86.23%
--------------------------------------------------
```
Построим ROC-кривую, показывающую качество классификации построенной логит-модели.

```stata
lroc
```
![](lroc.png)

попробуем построить ещё одну логит-модель без учёта фактора `white` и сохраним новую модель под именем `logit_model_new`.

```stata
logit smoke faminc cigtax cigprice fatheduc motheduc parity if fatheduc != . &amp; motheduc != .
est store logit_model_new
```

```
 translator Graph2png not found
r(111);



Iteration 0:   log likelihood = -471.77574  
Iteration 1:   log likelihood = -435.32968  
Iteration 2:   log likelihood = -432.55986  
Iteration 3:   log likelihood = -432.55452  
Iteration 4:   log likelihood = -432.55452  

Logistic regression                             Number of obs     =      1,191
                                                LR chi2(6)        =      78.44
                                                Prob &gt; chi2       =     0.0000
Log likelihood = -432.55452                     Pseudo R2         =     0.0831

------------------------------------------------------------------------------
       smoke |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      faminc |  -.0151861   .0062608    -2.43   0.015    -.0274571   -.0029151
      cigtax |   .0185624   .0242462     0.77   0.444    -.0289594    .0660842
    cigprice |   .0018681   .0182217     0.10   0.918    -.0338457     .037582
    fatheduc |   -.050238   .0412875    -1.22   0.224    -.1311599    .0306839
    motheduc |  -.2297778   .0489713    -4.69   0.000    -.3257597   -.1337959
      parity |  -.0182503   .0973743    -0.19   0.851    -.2091005    .1725998
       _cons |   1.509398   2.058132     0.73   0.463    -2.524467    5.543263
------------------------------------------------------------------------------
```
Сравним `logit_model` и `logit_model_new` с помощью LR (likelihood-ratio test):

```stata
lrtest logit_model logit_model_new
```

```
 translator Graph2png not found
r(111);


estimation result logit_model_new not found
r(111);

end of do-file
r(111);
```
`p-value = 0.08` в LR-тесте. Следовательно, основная гипотеза о том, что переменная `white` не влияет на решение стать курильщиком, не отвергается на 5% уровне значимости.

Построим пробит-модель и сохраним результат оцененной модели как `probit_model`.

```stata
probit smoke faminc cigtax cigprice fatheduc motheduc parity white if fatheduc != . &amp; motheduc != .
est store probit_model
```

```
 translator Graph2png not found
r(111);



Iteration 0:   log likelihood = -471.77574  
Iteration 1:   log likelihood = -430.54565  
Iteration 2:   log likelihood = -429.46543  
Iteration 3:   log likelihood = -429.46445  
Iteration 4:   log likelihood = -429.46445  

Probit regression                               Number of obs     =      1,191
                                                LR chi2(7)        =      84.62
                                                Prob &gt; chi2       =     0.0000
Log likelihood = -429.46445                     Pseudo R2         =     0.0897

------------------------------------------------------------------------------
       smoke |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      faminc |  -.0088727   .0033843    -2.62   0.009    -.0155058   -.0022396
      cigtax |   .0058916   .0131832     0.45   0.655    -.0199471    .0317303
    cigprice |   .0035612   .0098119     0.36   0.717    -.0156698    .0227921
    fatheduc |  -.0345932   .0232361    -1.49   0.137    -.0801351    .0109488
    motheduc |  -.1256938   .0271973    -4.62   0.000    -.1789995   -.0723882
      parity |  -.0030532   .0539655    -0.06   0.955    -.1088236    .1027172
       white |   .2423484   .1397166     1.73   0.083    -.0314911    .5161879
       _cons |   .3930625   1.115394     0.35   0.725     -1.79307    2.579195
------------------------------------------------------------------------------
```
Сравним коэффициенты построенных моделей: модели линейной вероятности, логит- и пробит-моделей.

```stata
est tab lin_prob_model logit_model probit_model
```

```
 translator Graph2png not found
r(111);


estimation result probit_model not found
r(111);

end of do-file
r(111);
```



&lt;!--chapter:end:03-binchoice.Rmd--&gt;

### Модели множественного выбора {#multchoice}




Загрузим необходимые пакеты.

```r
library(tidyverse) # для манипуляций с данными и построения графиков
library(skimr) # для красивого summary
library(rio) # для чтения .dta файлов
library(margins) # для расчета предельных эффектов
library(mlogit)
library(skimr)
library(nnet)
library(questionr)
library(MASS)
library(survival)
library(lattice)
```

## r

Импортируем датасет. В нем находятся данные по клиентам пенсионных фондов. Нас интересует переменная `pctstck`, которая принимает три значения: 0, 50, 100 - в зависимоcти от ответа респондента на вопрос о предпочтительном способе инвестирования пенсионных накоплений.   


```r
df = rio::import(&quot;data/pension.dta&quot;)
```


```r
skim_with(numeric = list(hist = NULL, p25 = NULL, p75 = NULL)) #посмотрим на данные

skim(df)
```

```
Skim summary statistics
 n obs: 226 
 n variables: 19 

── Variable type:numeric ───────────────────────────────────────────────────────────────────
 variable missing complete   n     mean      sd   p0     p50 p100
      age       0      226 226   60.7      4.29   53   60      73
    black       0      226 226    0.12     0.33    0    0       1
   choice       0      226 226    0.62     0.49    0    1       1
     educ       7      219 226   13.52     2.55    8   12      18
   female       0      226 226    0.6      0.49    0    1       1
  finc100      10      216 226    0.12     0.33    0    0       1
  finc101      10      216 226    0.065    0.25    0    0       1
   finc25      10      216 226    0.21     0.41    0    0       1
   finc35      10      216 226    0.19     0.39    0    0       1
   finc50      10      216 226    0.25     0.43    0    0       1
   finc75      10      216 226    0.12     0.33    0    0       1
       id       0      226 226 2445.09  1371.27   38 2377.5  5014
  irain89       0      226 226    0.5      0.5     0    0.5     1
  married       0      226 226    0.73     0.44    0    1       1
  pctstck       0      226 226   46.68    39.44    0   50     100
  prftshr      20      206 226    0.21     0.41    0    0       1
   pyears       8      218 226   11.39     9.61    0    9      45
 stckin89       0      226 226    0.32     0.47    0    0       1
 wealth89       0      226 226  197.91   242.09 -580  127.85 1485
```


Создадим факторную перменную и упорядочим категории. 


```r
df = mutate(df, y = factor(pctstck)) # факторная переменная
df = mutate(df, y = relevel(y, ref = 1)) # сменить базовую категорию
levels(df$y)
```

```
[1] &quot;0&quot;   &quot;50&quot;  &quot;100&quot;
```

Можно взглянуть на значения объясняемой переменной в разрезе какой-то другой переменной. Или посмотреть на картиночку.


```r
table(df$y, df$educ)
```

```
     
       8  9 10 11 12 13 14 15 16 17 18
  0    5  3  0  3 31  4  7  0 11  1  7
  50   1  1  0  3 34  4  6  2 14  5 14
  100  0  2  1  1 36  1  5  4  5  4  4
```

```r
tab = xtabs(~ y + educ, data = df)
prop.table(tab, 1)
```

```
     educ
y              8          9         10         11         12         13
  0   0.06944444 0.04166667 0.00000000 0.04166667 0.43055556 0.05555556
  50  0.01190476 0.01190476 0.00000000 0.03571429 0.40476190 0.04761905
  100 0.00000000 0.03174603 0.01587302 0.01587302 0.57142857 0.01587302
     educ
y             14         15         16         17         18
  0   0.09722222 0.00000000 0.15277778 0.01388889 0.09722222
  50  0.07142857 0.02380952 0.16666667 0.05952381 0.16666667
  100 0.07936508 0.06349206 0.07936508 0.06349206 0.06349206
```

```r
spineplot(tab, off = 0)
```

&lt;img src=&quot;04-multinom_choice_files/figure-html/unnamed-chunk-1-1.png&quot; width=&quot;672&quot; /&gt;

Построим модель множественного выбора (лог-линейная модель). 


```r
multmodel= multinom(y ~ choice+age+educ+wealth89+prftshr, data = df, reflevel = &#39;50&#39;)
```

```
# weights:  21 (12 variable)
initial  value 220.821070 
iter  10 value 207.012642
iter  20 value 204.507792
final  value 204.507779 
converged
```

```r
summary(multmodel)
```

```
Call:
multinom(formula = y ~ choice + age + educ + wealth89 + prftshr, 
    data = df, reflevel = &quot;50&quot;)

Coefficients:
    (Intercept)    choice         age       educ      wealth89    prftshr
50     3.777686 0.6269410 -0.10621691 0.18518113 -0.0003716626 -0.2717872
100    4.492971 0.6244954 -0.09482129 0.04644315 -0.0003548369  0.9809245

Std. Errors:
    (Intercept)    choice        age       educ     wealth89   prftshr
50     1.581691 0.3701263 0.02826469 0.06725443 0.0007365833 0.4988234
100    1.385291 0.3851273 0.02530600 0.07203058 0.0007896235 0.4396202

Residual Deviance: 409.0156 
AIC: 433.0156 
```

При необходимости можем построить модельку для подвыборки, например, только для замужних/женатых.


```r
multmodel_married = multinom(y ~ choice+age+educ+wealth89+prftshr, subset = married == 1, data = df, reflevel = &#39;50&#39;)
```

```
# weights:  21 (12 variable)
initial  value 165.890456 
iter  10 value 152.737765
iter  20 value 149.611359
final  value 149.611069 
converged
```

```r
summary(multmodel_married)
```

```
Call:
multinom(formula = y ~ choice + age + educ + wealth89 + prftshr, 
    data = df, subset = married == 1, reflevel = &quot;50&quot;)

Coefficients:
    (Intercept)    choice        age       educ      wealth89   prftshr
50     4.907315 1.0040978 -0.1279041 0.19054837 -0.0006204112 0.1901337
100    5.135424 0.4658502 -0.1145570 0.09046898 -0.0002127724 1.2594092

Std. Errors:
    (Intercept)    choice        age       educ     wealth89   prftshr
50     1.836616 0.4462543 0.03282248 0.07841324 0.0008456801 0.5624022
100    1.551829 0.4583930 0.02890949 0.08508466 0.0008605946 0.5228806

Residual Deviance: 299.2221 
AIC: 323.2221 
```

Быстренько прикинули значимость коэффициентов.


```r
summary(multmodel)$coefficients/summary(multmodel)$standard.errors
```

```
    (Intercept)   choice       age      educ   wealth89    prftshr
50     2.388384 1.693857 -3.757937 2.7534413 -0.5045765 -0.5448566
100    3.243342 1.621530 -3.746989 0.6447699 -0.4493748  2.2313001
```

Сохраним прогнозы.

```r
fit_values = fitted(multmodel)
```

И посчитать относительное изменение отношения шансов:

\[
\frac{P(y_{i} = j)}{P(y_{i} = 1)} = exp(x_{i}\beta)
\] - показывает изменение отношения шансов при выборе альтернативы j вместо альтернативы 0, если x изменился на единицу


```r
odds.ratio(multmodel) 
```

```
                      OR    2.5 %    97.5 %         p    
50/(Intercept)  43.71476  1.96920  970.4342 0.0169227 *  
50/choice        1.87188  0.90620    3.8666 0.0902925 .  
50/age           0.89923  0.85077    0.9505 0.0001713 ***
50/educ          1.20344  1.05481    1.3730 0.0058972 ** 
50/wealth89      0.99963  0.99819    1.0011 0.6138563    
50/prftshr       0.76202  0.28666    2.0256 0.5858522    
100/(Intercept) 89.38659  5.91713 1350.3111 0.0011814 ** 
100/choice       1.86730  0.87780    3.9722 0.1049041    
100/age          0.90954  0.86552    0.9558 0.0001790 ***
100/educ         1.04754  0.90961    1.2064 0.5190763    
100/wealth89     0.99965  0.99810    1.0012 0.6531613    
100/prftshr      2.66692  1.12669    6.3127 0.0256613 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
```


Можем посчитать предельные эффекты в различных квартилях. 


```r
summary(marginal_effects(multmodel)) 
```

```
  dydx_choice          dydx_age         dydx_educ        
 Min.   :-0.15646   Min.   :0.00887   Min.   :-0.036761  
 1st Qu.:-0.15043   1st Qu.:0.01777   1st Qu.:-0.029252  
 Median :-0.12909   Median :0.02075   Median :-0.025701  
 Mean   :-0.12697   Mean   :0.02049   Mean   :-0.024735  
 3rd Qu.:-0.10976   3rd Qu.:0.02411   3rd Qu.:-0.020634  
 Max.   :-0.05576   Max.   :0.02562   Max.   :-0.009214  
 dydx_wealth89        dydx_prftshr      
 Min.   :3.225e-05   Min.   :-0.177629  
 1st Qu.:6.389e-05   1st Qu.:-0.075981  
 Median :7.515e-05   Median :-0.056485  
 Mean   :7.385e-05   Mean   :-0.060746  
 3rd Qu.:8.726e-05   3rd Qu.:-0.023855  
 Max.   :9.123e-05   Max.   :-0.002558  
```

Допустим, мы можем упорядочить наши альтернативы (например, от более рискованного способа распределения ресурсов до менее). Тогда воспользуемся моделью упорядоченного выбора.


```r
logit.polr = polr(y ~ choice+age+educ+wealth89+prftshr , data = df)
probit.polr = polr(y ~ choice+age+educ+wealth89+prftshr , data = df, method = &#39;probit&#39;) 


### summary(logit.polr) не работает
```


```r
fit_prob = fitted(logit.polr)
fit_log = fitted(probit.polr)
```

## stata




```stata
use data/pension.dta
```
</code></pre>
<pre class="stata"><code>sum</code></pre>
<pre><code>    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          id |        226    2445.093    1371.271         38       5014
      pyears |        218    11.38532    9.605498          0         45
     prftshr |        206    .2087379    .4073967          0          1
      choice |        226    .6150442     .487665          0          1
      female |        226    .6017699      .49062          0          1
-------------+---------------------------------------------------------
     married |        226    .7345133    .4425723          0          1
         age |        226    60.70354    4.287002         53         73
        educ |        219    13.51598    2.554627          8         18
      finc25 |        216    .2083333    .4070598          0          1
      finc35 |        216    .1851852      .38935          0          1
-------------+---------------------------------------------------------
      finc50 |        216    .2453704    .4313061          0          1
      finc75 |        216        .125    .3314871          0          1
     finc100 |        216    .1203704      .32615          0          1
     finc101 |        216    .0648148    .2467707          0          1
    wealth89 |        226    197.9057    242.0919   -579.997   1484.997
-------------+---------------------------------------------------------
       black |        226     .119469    .3250596          0          1
    stckin89 |        226    .3185841    .4669616          0          1
     irain89 |        226          .5    .5011099          0          1
     pctstck |        226    46.68142    39.44116          0        100</code></pre>
<pre class="stata"><code>ren pctstck y</code></pre>
<pre><code>
Построим модель множественного выбора (лог-линейная модель). 

```stata
mlogit y choice age educ wealth89 prftshr,  baseoutcome(0) 
```

```
Iteration 0:   log likelihood = -219.86356  
Iteration 1:   log likelihood = -204.58172  
Iteration 2:   log likelihood =  -204.5078  
Iteration 3:   log likelihood = -204.50778  
Iteration 4:   log likelihood = -204.50778  

Multinomial logistic regression                 Number of obs     =        201
                                                LR chi2(10)       =      30.71
                                                Prob &gt; chi2       =     0.0007
Log likelihood = -204.50778                     Pseudo R2         =     0.0698

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
0            |  (base outcome)
-------------+----------------------------------------------------------------
50           |
      choice |   .6269473   .3706065     1.69   0.091    -.0994281    1.353323
         age |  -.1062189   .0434194    -2.45   0.014    -.1913193   -.0211185
        educ |   .1851821    .070641     2.62   0.009     .0467283    .3236359
    wealth89 |  -.0003717   .0007432    -0.50   0.617    -.0018283     .001085
     prftshr |  -.2718087   .4988312    -0.54   0.586      -1.2495    .7058825
       _cons |   3.777798   2.790118     1.35   0.176    -1.690732    9.246328
-------------+----------------------------------------------------------------
100          |
      choice |   .6244907   .3859169     1.62   0.106    -.1318925    1.380874
         age |  -.0948282   .0450488    -2.11   0.035    -.1831222   -.0065341
        educ |   .0464378   .0767858     0.60   0.545    -.1040595    .1969352
    wealth89 |  -.0003548    .000797    -0.45   0.656     -.001917    .0012074
     prftshr |   .9809114   .4396226     2.23   0.026      .119267    1.842556
       _cons |   4.493463   2.967396     1.51   0.130    -1.322526    10.30945
------------------------------------------------------------------------------
```

Можем посмотреть на прогнозы.


```stata
predict p1 p2 p3, p
```

```
(25 missing values generated)
```

И посчитать относительное изменение отношения шансов:

\[
\frac{P(y_{i} = j)}{P(y_{i} = 1)} = exp(x_{i}\beta)
\] - показывает изменение отношения шансов при выборе альтернативы j вместо альтернативы 0, если x изменился на единицу.
В stata, в отличие от R, отношение шансов называется relative-risk ratio.


```stata
mlogit, rrr
```

```
Multinomial logistic regression                 Number of obs     =        201
                                                LR chi2(10)       =      30.71
                                                Prob &gt; chi2       =     0.0007
Log likelihood = -204.50778                     Pseudo R2         =     0.0698

------------------------------------------------------------------------------
           y |        RRR   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
0            |  (base outcome)
-------------+----------------------------------------------------------------
50           |
      choice |   1.871888   .6937337     1.69   0.091     .9053551    3.870264
         age |   .8992278   .0390439    -2.45   0.014     .8258688     .979103
        educ |   1.203438    .085012     2.62   0.009     1.047837    1.382144
    wealth89 |   .9996284   .0007429    -0.50   0.617     .9981733    1.001086
     prftshr |       .762   .3801094    -0.54   0.586     .2866481    2.025633
       _cons |   43.71966    121.983     1.35   0.176     .1843845    10366.43
-------------+----------------------------------------------------------------
100          |
      choice |   1.867295   .7206205     1.62   0.106     .8764352    3.978377
         age |   .9095292   .0409732    -2.11   0.035     .8326664    .9934872
        educ |   1.047533   .0804356     0.60   0.545     .9011717    1.217665
    wealth89 |   .9996452   .0007968    -0.45   0.656     .9980848    1.001208
     prftshr |   2.666886   1.172423     2.23   0.026     1.126671    6.312652
       _cons |   89.43064   265.3761     1.51   0.130     .2664612    30015.02
------------------------------------------------------------------------------
```


Можем посчитать предельные эффекты в разных точках.


```stata
margins, predict(outcome(50)) dydx(choice age educ wealth89 prftshr) atmeans 

margins, predict(outcome(50)) dydx(choice age educ wealth89 prftshr) at((p25) *)
```

```
Conditional marginal effects                    Number of obs     =        201
Model VCE    : OIM

Expression   : Pr(y==50), predict(outcome(50))
dy/dx w.r.t. : choice age educ wealth89 prftshr
at           : choice          =    .6069652 (mean)
               age             =    60.52736 (mean)
               educ            =    13.56219 (mean)
               wealth89        =    205.5467 (mean)
               prftshr         =    .2089552 (mean)

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      choice |    .077144   .0757102     1.02   0.308    -.0712453    .2255333
         age |   -.014281   .0089754    -1.59   0.112    -.0318725    .0033105
        educ |   .0380169   .0140813     2.70   0.007     .0104182    .0656157
    wealth89 |  -.0000474   .0001544    -0.31   0.759      -.00035    .0002551
     prftshr |  -.1715698   .0989457    -1.73   0.083    -.3654998    .0223602
------------------------------------------------------------------------------


Conditional marginal effects                    Number of obs     =        201
Model VCE    : OIM

Expression   : Pr(y==50), predict(outcome(50))
dy/dx w.r.t. : choice age educ wealth89 prftshr
at           : choice          =           0 (p25)
               age             =          57 (p25)
               educ            =          12 (p25)
               wealth89        =        65.1 (p25)
               prftshr         =           0 (p25)

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      choice |   .0853087   .0708501     1.20   0.229    -.0535549    .2241723
         age |  -.0154741   .0095391    -1.62   0.105    -.0341705    .0032222
        educ |   .0380373   .0133192     2.86   0.004     .0119321    .0641426
    wealth89 |   -.000052    .000152    -0.34   0.732      -.00035     .000246
     prftshr |  -.1534241     .10697    -1.43   0.151    -.3630814    .0562333
------------------------------------------------------------------------------
```


Допустим, мы можем упорядочить наши альтернативы (например, от более рискованного способа распределения ресурсов до менее). Тогда воспользуемся моделью упорядоченного выбора.


```stata
oprobit y choice age educ wealth89 prftshr

ologit y choice age educ wealth89 prftshr
```

```
Iteration 0:   log likelihood = -219.86356  
Iteration 1:   log likelihood = -212.89234  
Iteration 2:   log likelihood = -212.88817  
Iteration 3:   log likelihood = -212.88817  

Ordered probit regression                       Number of obs     =        201
                                                LR chi2(5)        =      13.95
                                                Prob &gt; chi2       =     0.0159
Log likelihood = -212.88817                     Pseudo R2         =     0.0317

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      choice |   .2932272    .167064     1.76   0.079    -.0342122    .6206666
         age |  -.0453065   .0195009    -2.32   0.020    -.0835275   -.0070854
        educ |   .0269375   .0315643     0.85   0.393    -.0349273    .0888024
    wealth89 |  -.0001694   .0003431    -0.49   0.622    -.0008419    .0005031
     prftshr |   .4864833   .2030406     2.40   0.017      .088531    .8844355
-------------+----------------------------------------------------------------
       /cut1 |  -2.578052   1.277878                     -5.082648   -.0734562
       /cut2 |  -1.561798   1.272756                     -4.056353    .9327576
------------------------------------------------------------------------------


Iteration 0:   log likelihood = -219.86356  
Iteration 1:   log likelihood = -212.75117  
Iteration 2:   log likelihood = -212.72813  
Iteration 3:   log likelihood = -212.72813  

Ordered logistic regression                     Number of obs     =        201
                                                LR chi2(5)        =      14.27
                                                Prob &gt; chi2       =     0.0140
Log likelihood = -212.72813                     Pseudo R2         =     0.0325

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      choice |   .4720438   .2757545     1.71   0.087     -.068425    1.012513
         age |  -.0776337   .0328659    -2.36   0.018    -.1420497   -.0132177
        educ |   .0475714   .0514763     0.92   0.355    -.0533203    .1484631
    wealth89 |   -.000277    .000561    -0.49   0.621    -.0013765    .0008224
     prftshr |   .8312158   .3506528     2.37   0.018     .1439489    1.518483
-------------+----------------------------------------------------------------
       /cut1 |  -4.376271   2.144494                     -8.579402   -.1731395
       /cut2 |  -2.714186   2.129423                     -6.887779    1.459407
------------------------------------------------------------------------------
```




&lt;!--chapter:end:04-multinom_choice.Rmd--&gt;

# Модели упорядоченного выбора и условный логит {#ordchoice}




Загрузим необходимые пакеты.

```r
library(tidyverse) # для манипуляций с данными и построения графиков
library(skimr) #для красивого summary
library(rio) # для чтения .dta файлов
library(margins)
library(mlogit)
library(nnet)
library(questionr)
library(MASS)
library(survival)

# log(6)
```

Импортируем датасет. В нем находятся данные по клиентам пенсионных фондов. Нас интересует переменная `pctstck`, которая принимает три значения: 0, 50, 100 - в зависимоcти от ответа респондента на вопрос о предпочтительном способе инвестирования пенсионных накоплений.   

```r
df = rio::import(&quot;pension.dta&quot;)
```


```r
skim_with(numeric = list(hist = NULL, p25 = NULL, p75 = NULL)) #посмотрим на данные
#skim(df)
```


Создадим факторную перменную и упорядочим категории. 


```r
df = rename(df,  alloc = pctstck) # переименуем 
df = mutate(df, alloc_factor = factor(alloc)) # факторная переменная
df = mutate(df, y = relevel(df$alloc_factor, ref = 1)) # сменить базовую категорию
levels(df$y)
```

```
[1] &quot;0&quot;   &quot;50&quot;  &quot;100&quot;
```

Построим модель множественного выбора (лог-линейная модель). 

```r
multmodel = multinom(y ~ choice+age+educ+wealth89+prftshr, data = df)
```

```
# weights:  21 (12 variable)
initial  value 220.821070 
iter  10 value 207.012642
iter  20 value 204.507792
final  value 204.507779 
converged
```

```r
summary(multmodel)
```

```
Call:
multinom(formula = y ~ choice + age + educ + wealth89 + prftshr, 
    data = df)

Coefficients:
    (Intercept)    choice         age       educ      wealth89    prftshr
50     3.777686 0.6269410 -0.10621691 0.18518113 -0.0003716626 -0.2717872
100    4.492971 0.6244954 -0.09482129 0.04644315 -0.0003548369  0.9809245

Std. Errors:
    (Intercept)    choice        age       educ     wealth89   prftshr
50     1.581691 0.3701263 0.02826469 0.06725443 0.0007365833 0.4988234
100    1.385291 0.3851273 0.02530600 0.07203058 0.0007896235 0.4396202

Residual Deviance: 409.0156 
AIC: 433.0156 
```

Сохраним прогнозы.

```r
fit_values = fitted(multmodel)
head(fit_values)
```

```
          0        50       100
1 0.4040703 0.3308134 0.2651163
2 0.1534943 0.2619464 0.5845593
3 0.1651913 0.2342525 0.6005562
4 0.4300671 0.1504960 0.4194370
5 0.4878942 0.2797337 0.2323721
6 0.4642700 0.1265789 0.4091510
```

И посчитать относительное изменение отношения шансов:

\[
\frac{P(y_{i} = j)}{P(y_{i} = 1)} = exp(x_{i}\beta)
\] 
показывает изменение отношения шансов при выборе альтернативы j вместо альтернативы 0, если x изменился на единицу

```r
odds.ratio(multmodel) # отношение шансов в stata называется relative-risk ratio
```

```
                      OR    2.5 %    97.5 %         p    
50/(Intercept)  43.71476  1.96920  970.4342 0.0169227 *  
50/choice        1.87188  0.90620    3.8666 0.0902925 .  
50/age           0.89923  0.85077    0.9505 0.0001713 ***
50/educ          1.20344  1.05481    1.3730 0.0058972 ** 
50/wealth89      0.99963  0.99819    1.0011 0.6138563    
50/prftshr       0.76202  0.28666    2.0256 0.5858522    
100/(Intercept) 89.38659  5.91713 1350.3111 0.0011814 ** 
100/choice       1.86730  0.87780    3.9722 0.1049041    
100/age          0.90954  0.86552    0.9558 0.0001790 ***
100/educ         1.04754  0.90961    1.2064 0.5190763    
100/wealth89     0.99965  0.99810    1.0012 0.6531613    
100/prftshr      2.66692  1.12669    6.3127 0.0256613 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
```


Можем посчитать предельные эффекты в различных квартилях. 

```r
summary(marginal_effects(multmodel)) # mean как в стате
```

```
  dydx_choice          dydx_age         dydx_educ        
 Min.   :-0.15646   Min.   :0.00887   Min.   :-0.036761  
 1st Qu.:-0.15043   1st Qu.:0.01777   1st Qu.:-0.029252  
 Median :-0.12909   Median :0.02075   Median :-0.025701  
 Mean   :-0.12697   Mean   :0.02049   Mean   :-0.024735  
 3rd Qu.:-0.10976   3rd Qu.:0.02411   3rd Qu.:-0.020634  
 Max.   :-0.05576   Max.   :0.02562   Max.   :-0.009214  
 dydx_wealth89        dydx_prftshr      
 Min.   :3.225e-05   Min.   :-0.177629  
 1st Qu.:6.389e-05   1st Qu.:-0.075981  
 Median :7.515e-05   Median :-0.056485  
 Mean   :7.385e-05   Mean   :-0.060746  
 3rd Qu.:8.726e-05   3rd Qu.:-0.023855  
 Max.   :9.123e-05   Max.   :-0.002558  
```



Допустим, мы можем упорядочить наши альтернативы (например, от более рискованного способа распределения ресурсов до менее)

```r
ordered_logit = polr(y ~ choice+age+educ+wealth89+prftshr , data = df)
ordered_probit = polr(y ~ choice+age+educ+wealth89+prftshr , data = df, method = &#39;probit&#39;) 

fit_prob = fitted(ordered_probit)
fit_log = fitted(ordered_logit)
ordered_probit
```

```
Call:
polr(formula = y ~ choice + age + educ + wealth89 + prftshr, 
    data = df, method = &quot;probit&quot;)

Coefficients:
       choice           age          educ      wealth89       prftshr 
 0.2932276690 -0.0453064786  0.0269376562 -0.0001693805  0.4864824791 

Intercepts:
     0|50    50|100 
-2.578050 -1.561799 

Residual Deviance: 425.7763 
AIC: 439.7763 
(25 observations deleted due to missingness)
```

```r
ln(5)
```

```
Error in ln(5): could not find function &quot;ln&quot;
```



```r
cond_logit = clogit(y ~ choice+age+strata(educ)+wealth89+prftshr , data = df)
```

```
Error in coxph(formula = Surv(rep(1, 226L), y) ~ choice + age + strata(educ) + : Cox model doesn&#39;t support &quot;mright&quot; survival data
```

### То же самое в стате



```stata
use pension.dta
```

```
end of do-file
```


```stata
sum
```

```
    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          id |        226    2445.093    1371.271         38       5014
      pyears |        218    11.38532    9.605498          0         45
     prftshr |        206    .2087379    .4073967          0          1
      choice |        226    .6150442     .487665          0          1
      female |        226    .6017699      .49062          0          1
-------------+---------------------------------------------------------
     married |        226    .7345133    .4425723          0          1
         age |        226    60.70354    4.287002         53         73
        educ |        219    13.51598    2.554627          8         18
      finc25 |        216    .2083333    .4070598          0          1
      finc35 |        216    .1851852      .38935          0          1
-------------+---------------------------------------------------------
      finc50 |        216    .2453704    .4313061          0          1
      finc75 |        216        .125    .3314871          0          1
     finc100 |        216    .1203704      .32615          0          1
     finc101 |        216    .0648148    .2467707          0          1
    wealth89 |        226    197.9057    242.0919   -579.997   1484.997
-------------+---------------------------------------------------------
       black |        226     .119469    .3250596          0          1
    stckin89 |        226    .3185841    .4669616          0          1
     irain89 |        226          .5    .5011099          0          1
     pctstck |        226    46.68142    39.44116          0        100
```



```stata
ren pctstck alloc
```
</code></pre>
<p>Построим модель множественного выбора (лог-линейная модель).</p>
<pre class="stata"><code>mlogit alloc choice age educ wealth89 prftshr,  baseoutcome(0) #маленькое отличие с R</code></pre>
<pre><code>&gt; ичие с R
option # not allowed
r(198);

end of do-file
r(198);</code></pre>
<p>Можем посмотреть на прогнозы.</p>
<pre class="stata"><code>predict p1 p2 p3, p</code></pre>
<pre><code> option # not allowed
r(198);


last estimates not found
r(301);

end of do-file
r(301);</code></pre>
<p>И посчитать относительное изменение отношения шансов:</p>
<p><span class="math display">\[
\frac{P(y_{i} = j)}{P(y_{i} = 1)} = exp(x_{i}\beta)
\]</span> - показывает изменение отношения шансов при выборе альтернативы j вместо альтернативы 0, если x изменился на единицу</p>
<pre class="stata"><code>mlogit, rrr #relative-risk ratio</code></pre>
<pre><code> option # not allowed
r(198);


last estimates not found
r(301);

end of do-file
r(301);</code></pre>
<p>Можем посчитать предельные эффекты в разных точках.</p>
<pre class="stata"><code>margins, predict(outcome(50)) dydx( choice age educ wealth89 prftshr) atmeans 

margins, predict(outcome(50)) dydx( choice age educ wealth89 prftshr) at((p25) *)</code></pre>
<pre><code> option # not allowed
r(198);


last estimates not found
r(301);

end of do-file
r(301);</code></pre>
<pre class="stata"><code>oprobit alloc choice age educ wealth89 prftshr

ologit alloc choice age educ wealth89 prftshr</code></pre>
<pre><code> option # not allowed
r(198);



Iteration 0:   log likelihood = -219.86356  
Iteration 1:   log likelihood = -212.89234  
Iteration 2:   log likelihood = -212.88817  
Iteration 3:   log likelihood = -212.88817  

Ordered probit regression                       Number of obs     =        201
                                                LR chi2(5)        =      13.95
                                                Prob &gt; chi2       =     0.0159
Log likelihood = -212.88817                     Pseudo R2         =     0.0317

------------------------------------------------------------------------------
       alloc |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      choice |   .2932272    .167064     1.76   0.079    -.0342122    .6206666
         age |  -.0453065   .0195009    -2.32   0.020    -.0835275   -.0070854
        educ |   .0269375   .0315643     0.85   0.393    -.0349273    .0888024
    wealth89 |  -.0001694   .0003431    -0.49   0.622    -.0008419    .0005031
     prftshr |   .4864833   .2030406     2.40   0.017      .088531    .8844355
-------------+----------------------------------------------------------------
       /cut1 |  -2.578052   1.277878                     -5.082648   -.0734562
       /cut2 |  -1.561798   1.272756                     -4.056353    .9327576
------------------------------------------------------------------------------


Iteration 0:   log likelihood = -219.86356  
Iteration 1:   log likelihood = -212.75117  
Iteration 2:   log likelihood = -212.72813  
Iteration 3:   log likelihood = -212.72813  

Ordered logistic regression                     Number of obs     =        201
                                                LR chi2(5)        =      14.27
                                                Prob &gt; chi2       =     0.0140
Log likelihood = -212.72813                     Pseudo R2         =     0.0325

------------------------------------------------------------------------------
       alloc |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      choice |   .4720438   .2757545     1.71   0.087     -.068425    1.012513
         age |  -.0776337   .0328659    -2.36   0.018    -.1420497   -.0132177
        educ |   .0475714   .0514763     0.92   0.355    -.0533203    .1484631
    wealth89 |   -.000277    .000561    -0.49   0.621    -.0013765    .0008224
     prftshr |   .8312158   .3506528     2.37   0.018     .1439489    1.518483
-------------+----------------------------------------------------------------
       /cut1 |  -4.376271   2.144494                     -8.579402   -.1731395
       /cut2 |  -2.714186   2.129423                     -6.887779    1.459407
------------------------------------------------------------------------------</code></pre>
<p>Посмотрим на conditional logit</p>
<p>ПОКА ЗАБИЛА</p>
<pre class="stata"><code>
use crackers.dta


egen resp = group(id occ)

tabulate brand, generate(br)
rename br1 Sunshine
rename br2 Keebler
rename br3 Nabisco

clogit choice Sunshine Keebler Nabisco display feature price, group(resp)
</code></pre>
<pre><code> option # not allowed
r(198);


no; data in memory would be lost
r(4);

end of do-file
r(4);</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="installsoft.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="poisreg.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Rosetta_Stone.pdf", "Rosetta_Stone.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
